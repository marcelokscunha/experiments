{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a docker container for training/deploying our classifier\n",
    "In this exercise we'll create a Docker image that will have the required code for training and deploying a ML model. In this particular example, we'll use scikit-learn (https://scikit-learn.org/) and the **Random Forest Tree** implementation of that library to train a flower classifier. The dataset used in this experiment is a toy dataset called Iris (http://archive.ics.uci.edu/ml/datasets/iris). The clallenge itself is very basic, so you can focus on the mechanics and the features of this automated environment.\n",
    "\n",
    "A first pipeline will be executed at the end of this exercise, automatically. It will get the assets you'll push to a Git repo, build this image and push it to ECR, a docker image repository, used by SageMaker.\n",
    "\n",
    "> **Question**: Why would I create a Scikit-learn container from scratch if SageMaker already offerst one (https://docs.aws.amazon.com/sagemaker/latest/dg/sklearn.html).  \n",
    "> **Answer**: This is an exercise and the idea here is also to show you how you can create your own container. In a real-life scenario, the best approach is to use the native container offered by SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ecr_repository_name: iris-model\n",
      "account_id: 725879053979\n",
      "region: us-east-1\n",
      "role: arn:aws:iam::725879053979:role/MLOps\n",
      "bucket: sagemaker-us-east-1-725879053979\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "ecr_repository_name = 'iris-model'\n",
    "role = get_execution_role()\n",
    "account_id = role.split(':')[4]\n",
    "region = boto3.Session().region_name\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "print('ecr_repository_name:', ecr_repository_name)\n",
    "print('account_id:',account_id)\n",
    "print('region:',region)\n",
    "print('role:',role)\n",
    "print('bucket:',bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 1 - Creating the assets required to build/test a docker image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Let's start by creating the training script!\n",
    "\n",
    "As you can see, this is a very basic example of Scikit-Learn. Nothing fancy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf package\n",
    "!rm -rf docker\n",
    "\n",
    "!mkdir docker\n",
    "!mkdir docker/code\n",
    "\n",
    "!mkdir package\n",
    "!mkdir package/src\n",
    "!mkdir package/src/custom_lightgbm_inference\n",
    "!touch package/src/custom_lightgbm_inference/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile src/my_training.py\n",
    "# import os\n",
    "# import pandas as pd\n",
    "# import re\n",
    "# import joblib\n",
    "# import json\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# def load_dataset(path):\n",
    "#     # Take the set of files and read them all into a single pandas dataframe\n",
    "#     files = [ os.path.join(path, file) for file in os.listdir(path) ]\n",
    "    \n",
    "#     if len(files) == 0:\n",
    "#         raise ValueError(\"Invalid # of files in dir: {}\".format(path))\n",
    "\n",
    "#     raw_data = [ pd.read_csv(file, sep=\",\", header=None ) for file in files ]\n",
    "#     data = pd.concat(raw_data)\n",
    "\n",
    "#     # labels are in the first column\n",
    "#     y = data.iloc[:,0]\n",
    "#     X = data.iloc[:,1:]\n",
    "#     return X,y\n",
    "    \n",
    "# def main(args):\n",
    "#     print(\"Training mode\")\n",
    "\n",
    "#     try:\n",
    "#         X_train, y_train = load_dataset(args.training)\n",
    "#         X_test, y_test = load_dataset(args.testing)\n",
    "        \n",
    "#         hyperparameters = {\n",
    "#             \"max_depth\": args.max_depth,\n",
    "#             \"verbose\": 1, # show all logs\n",
    "#             \"n_jobs\": args.n_jobs,\n",
    "#             \"n_estimators\": args.n_estimators\n",
    "#         }\n",
    "#         print(\"Training the classifier\")\n",
    "#         model = RandomForestClassifier()\n",
    "#         model.set_params(**hyperparameters)\n",
    "#         model.fit(X_train, y_train)\n",
    "#         print(\"Score: {}\".format( model.score(X_test, y_test)) )\n",
    "#         joblib.dump(model, open(os.path.join(args.model_dir, \"iris_model.pkl\"), \"wb\"))\n",
    "    \n",
    "#     except Exception as e:\n",
    "#         # Write out an error file. This will be returned as the failureReason in the\n",
    "#         # DescribeTrainingJob result.\n",
    "#         trc = traceback.format_exc()\n",
    "#         with open(os.path.join(output_path, \"failure\"), \"w\") as s:\n",
    "#             s.write(\"Exception during training: \" + str(e) + \"\\\\n\" + trc)\n",
    "            \n",
    "#         # Printing this causes the exception to be in the training job logs, as well.\n",
    "#         print(\"Exception during training: \" + str(e) + \"\\\\n\" + trc, file=sys.stderr)\n",
    "        \n",
    "#         # A non-zero exit code causes the training job to be marked as Failed.\n",
    "#         sys.exit(255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Ok. Lets then create the handler. The **Inference Handler** is how we use the SageMaker Inference Toolkit to encapsulate our code and expose it as a SageMaker container.\n",
    "SageMaker Inference Toolkit: https://github.com/aws/sagemaker-inference-toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile src/handler_service.py\n",
    "# from sagemaker_inference.default_handler_service import DefaultHandlerService\n",
    "# from sagemaker_inference.transformer import Transformer\n",
    "# from inference_handler import CustomInferenceHandler\n",
    "\n",
    "# class HandlerService(DefaultHandlerService):\n",
    "#     def __init__(self):\n",
    "#         transformer = Transformer(default_inference_handler=CustomInferenceHandler())\n",
    "#         super(HandlerService, self).__init__(transformer=transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile src/inference_handler.py\n",
    "# import os\n",
    "# import sys\n",
    "# import joblib\n",
    "# from sagemaker_inference.default_inference_handler import DefaultInferenceHandler\n",
    "# from sagemaker_inference import content_types, errors, transformer, encoder, decoder\n",
    "\n",
    "# class CustomInferenceHandler(DefaultInferenceHandler):    \n",
    "#     ## Loads the model from the disk\n",
    "#     def default_model_fn(self, model_dir):\n",
    "#         model_filename = os.path.join(model_dir, \"model.joblib\")\n",
    "#         return joblib.load(model_filename)\n",
    "    \n",
    "#     ## Parse and check the format of the input data\n",
    "#     def default_input_fn(self, input_data, content_type):\n",
    "#         if content_type != \"text/csv\":\n",
    "#             raise Exception(\"Invalid content-type: %s\" % content_type)\n",
    "#         return decoder.decode(input_data, content_type).reshape(1,-1)\n",
    "    \n",
    "#     ## Run our model and do the prediction\n",
    "#     def default_predict_fn(self, payload, model):\n",
    "#         return model.predict( payload ).tolist()\n",
    "    \n",
    "#     ## Gets the prediction output and format it to be returned to the user\n",
    "#     def default_output_fn(self, prediction, accept):\n",
    "#         if accept != \"text/csv\":\n",
    "#             raise Exception(\"Invalid accept: %s\" % accept)\n",
    "#         return encoder.encode(prediction, accept)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing package/src/custom_lightgbm_inference/handler.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile package/src/custom_lightgbm_inference/handler.py\n",
    "# !pygmentize package/src/custom_lightgbm_inference/handler.py\n",
    "import os\n",
    "import sys\n",
    "import joblib\n",
    "from sagemaker_inference.default_inference_handler import DefaultInferenceHandler\n",
    "from sagemaker_inference.default_handler_service import DefaultHandlerService\n",
    "from sagemaker_inference import content_types, errors, transformer, encoder, decoder\n",
    "\n",
    "class HandlerService(DefaultHandlerService, DefaultInferenceHandler):\n",
    "    def __init__(self):\n",
    "        op = transformer.Transformer(default_inference_handler=self)\n",
    "        super(HandlerService, self).__init__(transformer=op)\n",
    "    \n",
    "    ## Loads the model from the disk\n",
    "    def default_model_fn(self, model_dir):\n",
    "        model_filename = os.path.join(model_dir, \"model.joblib\")\n",
    "        return joblib.load(model_filename)\n",
    "    \n",
    "    ## Parse and check the format of the input data\n",
    "    def default_input_fn(self, input_data, content_type):\n",
    "        if content_type != \"text/csv\":\n",
    "            raise Exception(\"Invalid content-type: %s\" % content_type)\n",
    "        return decoder.decode(input_data, content_type).reshape(1,-1)\n",
    "    \n",
    "    ## Run our model and do the prediction\n",
    "    def default_predict_fn(self, payload, model):\n",
    "        return model.predict( payload ).tolist()\n",
    "    \n",
    "    ## Gets the prediction output and format it to be returned to the user\n",
    "    def default_output_fn(self, prediction, accept):\n",
    "        if accept != \"text/csv\":\n",
    "            raise Exception(\"Invalid accept: %s\" % accept)\n",
    "        return encoder.encode(prediction, accept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Now we need to create the entrypoint of our container. The main function\n",
    "\n",
    "We'll use **SageMaker Training Toolkit** (https://github.com/aws/sagemaker-training-toolkit) to work with the arguments and environment variables defined by SageMaker. This library will make our code simpler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing package/src/custom_lightgbm_inference/my_serving.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile package/src/custom_lightgbm_inference/my_serving.py\n",
    "# !pygmentize package/src/custom_lightgbm_inference/my_serving.py\n",
    "\n",
    "from sagemaker_inference import model_server\n",
    "from custom_lightgbm_inference import handler\n",
    "\n",
    "HANDLER_SERVICE = handler.__name__\n",
    "\n",
    "def main():\n",
    "    print('Running handler service:', HANDLER_SERVICE)\n",
    "    model_server.start_model_server(handler_service=HANDLER_SERVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing package/setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile package/setup.py\n",
    "# !pygmentize package/setup.py\n",
    "\n",
    "from __future__ import absolute_import\n",
    "\n",
    "from glob import glob\n",
    "import os\n",
    "from os.path import basename\n",
    "from os.path import splitext\n",
    "\n",
    "from setuptools import find_packages, setup\n",
    "\n",
    "setup(\n",
    "    name='custom_lightgbm_inference',\n",
    "    version='0.1.0',\n",
    "    description='Custom container serving package for SageMaker.',\n",
    "    keywords=\"custom container serving package SageMaker\",\n",
    "\n",
    "    packages=find_packages(where='src'),\n",
    "    package_dir={'': 'src'},\n",
    "    py_modules=[splitext(basename(path))[0] for path in glob('src/*.py')],\n",
    "    \n",
    "    install_requires=[\n",
    "        'sagemaker-inference==1.3.0',\n",
    "        'multi-model-server==1.1.2'\n",
    "    ],\n",
    "    entry_points={\"console_scripts\": [\"serve=custom_lightgbm_inference.my_serving:main\"]},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile setup.py\n",
    "\n",
    "# from __future__ import absolute_import\n",
    "\n",
    "# from glob import glob\n",
    "# import os\n",
    "# from os.path import basename\n",
    "# from os.path import splitext\n",
    "\n",
    "# from setuptools import find_packages, setup\n",
    "\n",
    "# setup(\n",
    "#     name='sagemaker-custom',\n",
    "#     version='0.1.0',\n",
    "#     description='Custom container serving package for SageMaker.',\n",
    "#     keywords=\"custom container serving package SageMaker\",\n",
    "\n",
    "#     packages=find_packages(where='src'),\n",
    "#     package_dir={'': 'src'},\n",
    "#     py_modules=[splitext(basename(path))[0] for path in glob('src/*.py')],\n",
    "    \n",
    "#     install_requires=['sagemaker-inference==1.3.0'],\n",
    "#     entry_points={\"console_scripts\": [\"serve=custom_inference.cli.init_serve:main\"]},\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile src/cli/init_serve.py\n",
    "\n",
    "# import os\n",
    "\n",
    "# def main():\n",
    "#     serving_module = os.environ.get('SAGEMAKER_SERVING_MODULE')\n",
    "\n",
    "#     serving_name, entry_point_name = serving_module.split(\":\")\n",
    "\n",
    "#     serving = importlib.import_module(serving_name)\n",
    "\n",
    "#     # the logger is configured after importing the framework library, allowing\n",
    "#     # the framework to configure logging at import time.\n",
    "#     logging_config.configure_logger(env.log_level)\n",
    "#     logger.info(\"Using serving module %s\", serving_name)\n",
    "\n",
    "#     entrypoint = getattr(serving, entry_point_name)\n",
    "#     entrypoint()\n",
    "    \n",
    "# if __name__=='__main__':\n",
    "#     main()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sagemaker-training sagemaker-inference multi-model-server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///home/ec2-user/SageMaker/sagemaker_custom/1_custom_inference/package\n",
      "Requirement already satisfied: sagemaker-inference==1.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from custom-lightgbm-inference==0.1.0) (1.3.0)\n",
      "Requirement already satisfied: multi-model-server==1.1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from custom-lightgbm-inference==0.1.0) (1.1.2)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sagemaker-inference==1.3.0->custom-lightgbm-inference==0.1.0) (5.7.0)\n",
      "Requirement already satisfied: typing in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sagemaker-inference==1.3.0->custom-lightgbm-inference==0.1.0) (3.7.4.3)\n",
      "Requirement already satisfied: retrying==1.3.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sagemaker-inference==1.3.0->custom-lightgbm-inference==0.1.0) (1.3.3)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sagemaker-inference==1.3.0->custom-lightgbm-inference==0.1.0) (1.18.1)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sagemaker-inference==1.3.0->custom-lightgbm-inference==0.1.0) (1.14.0)\n",
      "Requirement already satisfied: future in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from multi-model-server==1.1.2->custom-lightgbm-inference==0.1.0) (0.18.2)\n",
      "Requirement already satisfied: model-archiver in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from multi-model-server==1.1.2->custom-lightgbm-inference==0.1.0) (1.0.3)\n",
      "Requirement already satisfied: Pillow in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from multi-model-server==1.1.2->custom-lightgbm-inference==0.1.0) (7.0.0)\n",
      "Requirement already satisfied: enum-compat in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from model-archiver->multi-model-server==1.1.2->custom-lightgbm-inference==0.1.0) (0.0.3)\n",
      "Installing collected packages: custom-lightgbm-inference\n",
      "  Attempting uninstall: custom-lightgbm-inference\n",
      "    Found existing installation: custom-lightgbm-inference 0.1.0\n",
      "    Uninstalling custom-lightgbm-inference-0.1.0:\n",
      "      Successfully uninstalled custom-lightgbm-inference-0.1.0\n",
      "  Running setup.py develop for custom-lightgbm-inference\n",
      "Successfully installed custom-lightgbm-inference\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.2 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!cd package && pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running sdist\n",
      "running egg_info\n",
      "writing src/custom_lightgbm_inference.egg-info/PKG-INFO\n",
      "writing dependency_links to src/custom_lightgbm_inference.egg-info/dependency_links.txt\n",
      "writing entry points to src/custom_lightgbm_inference.egg-info/entry_points.txt\n",
      "writing requirements to src/custom_lightgbm_inference.egg-info/requires.txt\n",
      "writing top-level names to src/custom_lightgbm_inference.egg-info/top_level.txt\n",
      "reading manifest file 'src/custom_lightgbm_inference.egg-info/SOURCES.txt'\n",
      "writing manifest file 'src/custom_lightgbm_inference.egg-info/SOURCES.txt'\n",
      "warning: sdist: standard file not found: should have one of README, README.rst, README.txt, README.md\n",
      "\n",
      "running check\n",
      "warning: check: missing required meta-data: url\n",
      "\n",
      "warning: check: missing meta-data: either (author and author_email) or (maintainer and maintainer_email) must be supplied\n",
      "\n",
      "creating custom_lightgbm_inference-0.1.0\n",
      "creating custom_lightgbm_inference-0.1.0/src\n",
      "creating custom_lightgbm_inference-0.1.0/src/custom_lightgbm_inference\n",
      "creating custom_lightgbm_inference-0.1.0/src/custom_lightgbm_inference.egg-info\n",
      "copying files to custom_lightgbm_inference-0.1.0...\n",
      "copying setup.py -> custom_lightgbm_inference-0.1.0\n",
      "copying src/custom_lightgbm_inference/__init__.py -> custom_lightgbm_inference-0.1.0/src/custom_lightgbm_inference\n",
      "copying src/custom_lightgbm_inference/handler.py -> custom_lightgbm_inference-0.1.0/src/custom_lightgbm_inference\n",
      "copying src/custom_lightgbm_inference/my_serving.py -> custom_lightgbm_inference-0.1.0/src/custom_lightgbm_inference\n",
      "copying src/custom_lightgbm_inference.egg-info/PKG-INFO -> custom_lightgbm_inference-0.1.0/src/custom_lightgbm_inference.egg-info\n",
      "copying src/custom_lightgbm_inference.egg-info/SOURCES.txt -> custom_lightgbm_inference-0.1.0/src/custom_lightgbm_inference.egg-info\n",
      "copying src/custom_lightgbm_inference.egg-info/dependency_links.txt -> custom_lightgbm_inference-0.1.0/src/custom_lightgbm_inference.egg-info\n",
      "copying src/custom_lightgbm_inference.egg-info/entry_points.txt -> custom_lightgbm_inference-0.1.0/src/custom_lightgbm_inference.egg-info\n",
      "copying src/custom_lightgbm_inference.egg-info/requires.txt -> custom_lightgbm_inference-0.1.0/src/custom_lightgbm_inference.egg-info\n",
      "copying src/custom_lightgbm_inference.egg-info/top_level.txt -> custom_lightgbm_inference-0.1.0/src/custom_lightgbm_inference.egg-info\n",
      "Writing custom_lightgbm_inference-0.1.0/setup.cfg\n",
      "creating dist\n",
      "Creating tar archive\n",
      "removing 'custom_lightgbm_inference-0.1.0' (and everything under it)\n"
     ]
    }
   ],
   "source": [
    "!cd package/ && python setup.py sdist && cp dist/custom_lightgbm_inference-0.1.0.tar.gz ../docker/code/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running handler service: custom_lightgbm_inference.handler\n",
      "ERROR - Given model-path /opt/ml/model is not a valid directory. Point to a valid model-path directory.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/bin/serve\", line 11, in <module>\n",
      "    load_entry_point('custom-lightgbm-inference', 'console_scripts', 'serve')()\n",
      "  File \"/home/ec2-user/SageMaker/sagemaker_custom/1_custom_inference/package/src/custom_lightgbm_inference/my_serving.py\", line 10, in main\n",
      "    model_server.start_model_server(handler_service=HANDLER_SERVICE)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker_inference/model_server.py\", line 75, in start_model_server\n",
      "    _adapt_to_mms_format(handler_service)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker_inference/model_server.py\", line 122, in _adapt_to_mms_format\n",
      "    subprocess.check_call(model_archiver_cmd)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/subprocess.py\", line 311, in check_call\n",
      "    raise CalledProcessError(retcode, cmd)\n",
      "subprocess.CalledProcessError: Command '['model-archiver', '--model-name', 'model', '--handler', 'custom_lightgbm_inference.handler', '--model-path', '/opt/ml/model', '--export-path', '/home/ec2-user/SageMaker/sagemaker_custom/1_custom_inference/.sagemaker/mms/models', '--archive-format', 'no-archive']' returned non-zero exit status 1.\n"
     ]
    }
   ],
   "source": [
    "!serve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Then, we can create the Dockerfile\n",
    "Just pay attention to the packages we'll install in our container. Here, we'll use **SageMaker Inference Toolkit** (https://github.com/aws/sagemaker-inference-toolkit) and **SageMaker Training Toolkit** (https://github.com/aws/sagemaker-training-toolkit) to prepare the container for training/serving our model. **By serving** you can understand: exposing our model as a webservice that can be called through an api call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile Dockerfile\n",
    "# FROM python:3.7-buster\n",
    "\n",
    "# # Set a docker label to advertise multi-model support on the container\n",
    "# LABEL com.amazonaws.sagemaker.capabilities.multi-models=false\n",
    "# # Set a docker label to enable container to use SAGEMAKER_BIND_TO_PORT environment variable if present\n",
    "# LABEL com.amazonaws.sagemaker.capabilities.accept-bind-to-port=true\n",
    "\n",
    "# RUN apt-get update -y && apt-get -y install --no-install-recommends default-jdk\n",
    "# RUN rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "# RUN pip --no-cache-dir install multi-model-server sagemaker-inference sagemaker-training\n",
    "# RUN pip --no-cache-dir install pandas numpy scipy scikit-learn\n",
    "\n",
    "# COPY dist/sagemaker-custom-0.1.0.tar.gz /sagemaker-custom-0.1.0.tar.gz\n",
    "# RUN pip --no-cache install /sagemaker-custom-0.1.0.tar.gz && \\\n",
    "#     rm /sagemaker-custom-0.1.0.tar.gz\n",
    "\n",
    "# ENV PYTHONUNBUFFERED=TRUE\n",
    "# ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
    "# ENV PYTHONPATH=\"/opt/ml/code:${PATH}\"\n",
    "\n",
    "# #####################\n",
    "# # Required ENV vars #\n",
    "# #####################\n",
    "# # Set SageMaker training environment variables\n",
    "# ENV SM_INPUT /opt/ml/input\n",
    "# ENV SM_INPUT_TRAINING_CONFIG_FILE $SM_INPUT/config/hyperparameters.json\n",
    "# ENV SM_INPUT_DATA_CONFIG_FILE $SM_INPUT/config/inputdataconfig.json\n",
    "# ENV SM_CHECKPOINT_CONFIG_FILE $SM_INPUT/config/checkpointconfig.json\n",
    "\n",
    "# # Set SageMaker serving environment variables\n",
    "# ENV SM_MODEL_DIR /opt/ml/model\n",
    "\n",
    "# ENV CODE_DIR /opt/ml/code\n",
    "# # COPY main.py $CODE_DIR/main.py\n",
    "# COPY src/my_training.py $CODE_DIR/my_training.py\n",
    "# COPY src/my_serving.py $CODE_DIR/my_serving.py\n",
    "\n",
    "# COPY src/handler_service.py $CODE_DIR/handler_service.py\n",
    "# COPY src/inference_handler.py $CODE_DIR/inference_handler.py\n",
    "\n",
    "# ENV SAGEMAKER_TRAINING_MODULE my_training:main\n",
    "# ENV SAGEMAKER_SERVING_MODULE my_serving:main\n",
    "\n",
    "# # ENTRYPOINT [\"python\", \"/opt/ml/code/main.py\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing docker/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile docker/Dockerfile\n",
    "# !pygmentize docker/Dockerfile\n",
    "\n",
    "# Part of the implementation of this container is based on the Amazon SageMaker Apache MXNet container.\n",
    "# https://github.com/aws/sagemaker-mxnet-container\n",
    "FROM sagemaker-training-containers/framework-container:latest\n",
    "\n",
    "# Defining some variables used at build time to install Python3\n",
    "ARG PYTHON=python3\n",
    "ARG PYTHON_PIP=python3-pip\n",
    "ARG PIP=pip3\n",
    "ARG PYTHON_VERSION=3.6.6\n",
    "\n",
    "\n",
    "# Framework Training docker\n",
    "# COPY code/custom_lightgbm_framework-1.0.0.tar.gz /custom_lightgbm_framework-1.0.0.tar.gz\n",
    "\n",
    "# Installing numpy, pandas, scikit-learn, scipy\n",
    "# RUN ${PIP} install --no-cache --upgrade \\\n",
    "#         /custom_lightgbm_framework-1.0.0.tar.gz && \\\n",
    "#     rm /custom_lightgbm_framework-1.0.0.tar.gz\n",
    "\n",
    "# Setting some environment variables.\n",
    "# ENV PYTHONDONTWRITEBYTECODE=1 \\\n",
    "#     PYTHONUNBUFFERED=1 \\\n",
    "#     LD_LIBRARY_PATH=\"${LD_LIBRARY_PATH}:/usr/local/lib\" \\\n",
    "#     PYTHONIOENCODING=UTF-8 \\\n",
    "#     LANG=C.UTF-8 \\\n",
    "#     LC_ALL=C.UTF-8\n",
    "\n",
    "\n",
    "# Set a docker label to advertise multi-model support on the container\n",
    "LABEL com.amazonaws.sagemaker.capabilities.multi-models=false\n",
    "# Set a docker label to enable container to use SAGEMAKER_BIND_TO_PORT environment variable if present\n",
    "LABEL com.amazonaws.sagemaker.capabilities.accept-bind-to-port=true\n",
    "\n",
    "\n",
    "# Previous inference docker\n",
    "RUN apt-get update -y && apt-get -y install --no-install-recommends default-jdk\n",
    "RUN rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "# RUN pip --no-cache-dir install multi-model-server sagemaker-inference sagemaker-training\n",
    "# RUN pip --no-cache-dir install pandas numpy scipy scikit-learn\n",
    "\n",
    "COPY code/custom_lightgbm_inference-0.1.0.tar.gz /custom_lightgbm_inference-0.1.0.tar.gz\n",
    "        \n",
    "RUN ${PIP} install --no-cache --upgrade \\\n",
    "        /custom_lightgbm_inference-0.1.0.tar.gz && \\\n",
    "    rm /custom_lightgbm_inference-0.1.0.tar.gz\n",
    "\n",
    "# ENV PYTHONUNBUFFERED=TRUE\n",
    "# ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
    "# ENV PYTHONPATH=\"/opt/ml/code:${PATH}\"\n",
    "\n",
    "#####################\n",
    "# Required ENV vars #\n",
    "#####################\n",
    "# Set SageMaker training environment variables\n",
    "# ENV SM_INPUT /opt/ml/input\n",
    "# ENV SM_INPUT_TRAINING_CONFIG_FILE $SM_INPUT/config/hyperparameters.json\n",
    "# ENV SM_INPUT_DATA_CONFIG_FILE $SM_INPUT/config/inputdataconfig.json\n",
    "# ENV SM_CHECKPOINT_CONFIG_FILE $SM_INPUT/config/checkpointconfig.json\n",
    "\n",
    "# Set SageMaker serving environment variables\n",
    "ENV SM_MODEL_DIR /opt/ml/model\n",
    "\n",
    "ENV CODE_DIR /opt/ml/code\n",
    "# COPY main.py $CODE_DIR/main.py\n",
    "\n",
    "# COPY src/my_serving.py $CODE_DIR/my_serving.py\n",
    "\n",
    "# COPY src/handler_service.py $CODE_DIR/handler_service.py\n",
    "# COPY src/inference_handler.py $CODE_DIR/inference_handler.py\n",
    "\n",
    "# ENV SAGEMAKER_TRAINING_MODULE my_training:main\n",
    "\n",
    "#Not injecting inference code, hence no need for env var\n",
    "# ENV SAGEMAKER_SERVING_MODULE my_serving:main\n",
    "\n",
    "# ENTRYPOINT [\"python\", \"/opt/ml/code/main.py\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Finally, let's create the buildspec\n",
    "This file will be used by CodeBuild for creating our Container image.  \n",
    "With this file, CodeBuild will run the \"docker build\" command, using the assets we created above, and deploy the image to the Registry.  \n",
    "As you can see, each command is a bash command that will be executed from inside a Linux Container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting buildspec.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile buildspec.yml\n",
    "version: 0.2\n",
    "\n",
    "phases:\n",
    "  install:\n",
    "    runtime-versions:\n",
    "      docker: 18\n",
    "\n",
    "  pre_build:\n",
    "    commands:\n",
    "      - echo Logging in to Amazon ECR...\n",
    "      - $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION)\n",
    "  build:\n",
    "    commands:\n",
    "      - echo Build started on `date`\n",
    "      - echo Building the Docker image...\n",
    "      - docker build -t $IMAGE_REPO_NAME:$IMAGE_TAG .\n",
    "      - docker tag $IMAGE_REPO_NAME:$IMAGE_TAG $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG\n",
    "\n",
    "  post_build:\n",
    "    commands:\n",
    "      - echo Build completed on `date`\n",
    "      - echo Pushing the Docker image...\n",
    "      - echo docker push $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG\n",
    "      - docker push $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG\n",
    "      - echo $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG > image.url\n",
    "      - echo Done\n",
    "artifacts:\n",
    "  files:\n",
    "    - image.url\n",
    "  name: image_url\n",
    "  discard-paths: yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 2 - Local Test: Let's build the image locally and do some tests\n",
    "### 2.1 Building the image locally, first\n",
    "Each SageMaker Jupyter Notebook already has a **docker** envorinment pre-installed. So we can play with Docker containers just using the same environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building and pushing to ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon   7.68kB\n",
      "Step 1/13 : FROM sagemaker-training-containers/framework-container:latest\n",
      " ---> 6e6a47cf0f36\n",
      "Step 2/13 : ARG PYTHON=python3\n",
      " ---> Using cache\n",
      " ---> a8cb49fa3ec4\n",
      "Step 3/13 : ARG PYTHON_PIP=python3-pip\n",
      " ---> Using cache\n",
      " ---> 7096781dc9d8\n",
      "Step 4/13 : ARG PIP=pip3\n",
      " ---> Using cache\n",
      " ---> 30b0cfbde1dc\n",
      "Step 5/13 : ARG PYTHON_VERSION=3.6.6\n",
      " ---> Using cache\n",
      " ---> 65862c7be643\n",
      "Step 6/13 : LABEL com.amazonaws.sagemaker.capabilities.multi-models=false\n",
      " ---> Using cache\n",
      " ---> 3c6656952914\n",
      "Step 7/13 : LABEL com.amazonaws.sagemaker.capabilities.accept-bind-to-port=true\n",
      " ---> Using cache\n",
      " ---> 8c6ac00dd42a\n",
      "Step 8/13 : RUN apt-get update -y && apt-get -y install --no-install-recommends default-jdk\n",
      " ---> Running in 076974884a35\n",
      "Get:1 http://security.ubuntu.com/ubuntu xenial-security InRelease [109 kB]\n",
      "Hit:2 http://archive.ubuntu.com/ubuntu xenial InRelease\n",
      "Hit:3 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu xenial InRelease\n",
      "Get:4 http://security.ubuntu.com/ubuntu xenial-security/main amd64 Packages [1160 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu xenial-updates InRelease [109 kB]\n",
      "Get:6 http://security.ubuntu.com/ubuntu xenial-security/universe amd64 Packages [635 kB]\n",
      "Get:7 http://security.ubuntu.com/ubuntu xenial-security/multiverse amd64 Packages [6680 B]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu xenial-backports InRelease [107 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 Packages [1520 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu xenial-updates/universe amd64 Packages [1036 kB]\n",
      "Fetched 4682 kB in 1s (4114 kB/s)\n",
      "Reading package lists...\n",
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "The following additional packages will be installed:\n",
      "  ca-certificates-java default-jdk-headless default-jre default-jre-headless\n",
      "  java-common libasound2 libasound2-data libasyncns0 libflac8 libgif7\n",
      "  liblcms2-2 libnspr4 libnss3 libnss3-nssdb libpcsclite1 libpulse0 libsndfile1\n",
      "  libxtst6 openjdk-8-jdk openjdk-8-jdk-headless openjdk-8-jre\n",
      "  openjdk-8-jre-headless\n",
      "Suggested packages:\n",
      "  default-java-plugin libasound2-plugins alsa-utils liblcms2-utils pcscd\n",
      "  pulseaudio openjdk-8-demo openjdk-8-source visualvm icedtea-8-plugin\n",
      "  libnss-mdns fonts-dejavu-extra fonts-ipafont-gothic fonts-ipafont-mincho\n",
      "  fonts-wqy-microhei fonts-wqy-zenhei fonts-indic\n",
      "Recommended packages:\n",
      "  fonts-dejavu-extra\n",
      "The following NEW packages will be installed:\n",
      "  ca-certificates-java default-jdk default-jdk-headless default-jre\n",
      "  default-jre-headless java-common libasound2 libasound2-data libasyncns0\n",
      "  libflac8 libgif7 liblcms2-2 libnspr4 libnss3 libnss3-nssdb libpcsclite1\n",
      "  libpulse0 libsndfile1 libxtst6 openjdk-8-jdk openjdk-8-jdk-headless\n",
      "  openjdk-8-jre openjdk-8-jre-headless\n",
      "0 upgraded, 23 newly installed, 0 to remove and 3 not upgraded.\n",
      "Need to get 39.5 MB of archives.\n",
      "After this operation, 150 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu xenial/main amd64 libasyncns0 amd64 0.8-5build1 [12.3 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu xenial/main amd64 libxtst6 amd64 2:1.2.2-1 [14.1 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu xenial/main amd64 java-common all 0.56ubuntu2 [7742 B]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 liblcms2-2 amd64 2.6-3ubuntu2.1 [136 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libnspr4 amd64 2:4.13.1-0ubuntu0.16.04.1 [112 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libnss3-nssdb all 2:3.28.4-0ubuntu0.16.04.13 [10.6 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libnss3 amd64 2:3.28.4-0ubuntu0.16.04.13 [1231 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libpcsclite1 amd64 1.8.14-1ubuntu1.16.04.1 [21.4 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 openjdk-8-jre-headless amd64 8u265-b01-0ubuntu2~16.04 [27.2 MB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu xenial/main amd64 default-jre-headless amd64 2:1.8-56ubuntu2 [4380 B]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 ca-certificates-java all 20160321ubuntu1 [12.5 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu xenial/main amd64 libasound2-data all 1.1.0-0ubuntu1 [29.4 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu xenial/main amd64 libasound2 amd64 1.1.0-0ubuntu1 [350 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libgif7 amd64 5.1.4-0.3~16.04.1 [30.5 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu xenial/main amd64 libflac8 amd64 1.3.1-4 [210 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libsndfile1 amd64 1.0.25-10ubuntu0.16.04.2 [139 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libpulse0 amd64 1:8.0-0ubuntu3.12 [253 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 openjdk-8-jre amd64 8u265-b01-0ubuntu2~16.04 [69.2 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu xenial/main amd64 default-jre amd64 2:1.8-56ubuntu2 [980 B]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 openjdk-8-jdk-headless amd64 8u265-b01-0ubuntu2~16.04 [8213 kB]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu xenial/main amd64 default-jdk-headless amd64 2:1.8-56ubuntu2 [986 B]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 openjdk-8-jdk amd64 8u265-b01-0ubuntu2~16.04 [1453 kB]\n",
      "Get:23 http://archive.ubuntu.com/ubuntu xenial/main amd64 default-jdk amd64 2:1.8-56ubuntu2 [968 B]\n",
      "\u001b[91mdebconf: delaying package configuration, since apt-utils is not installed\n",
      "\u001b[0mFetched 39.5 MB in 1s (22.4 MB/s)\n",
      "Selecting previously unselected package libasyncns0:amd64.\n",
      "(Reading database ... 23053 files and directories currently installed.)\n",
      "Preparing to unpack .../libasyncns0_0.8-5build1_amd64.deb ...\n",
      "Unpacking libasyncns0:amd64 (0.8-5build1) ...\n",
      "Selecting previously unselected package libxtst6:amd64.\n",
      "Preparing to unpack .../libxtst6_2%3a1.2.2-1_amd64.deb ...\n",
      "Unpacking libxtst6:amd64 (2:1.2.2-1) ...\n",
      "Selecting previously unselected package java-common.\n",
      "Preparing to unpack .../java-common_0.56ubuntu2_all.deb ...\n",
      "Unpacking java-common (0.56ubuntu2) ...\n",
      "Selecting previously unselected package liblcms2-2:amd64.\n",
      "Preparing to unpack .../liblcms2-2_2.6-3ubuntu2.1_amd64.deb ...\n",
      "Unpacking liblcms2-2:amd64 (2.6-3ubuntu2.1) ...\n",
      "Selecting previously unselected package libnspr4:amd64.\n",
      "Preparing to unpack .../libnspr4_2%3a4.13.1-0ubuntu0.16.04.1_amd64.deb ...\n",
      "Unpacking libnspr4:amd64 (2:4.13.1-0ubuntu0.16.04.1) ...\n",
      "Selecting previously unselected package libnss3-nssdb.\n",
      "Preparing to unpack .../libnss3-nssdb_2%3a3.28.4-0ubuntu0.16.04.13_all.deb ...\n",
      "Unpacking libnss3-nssdb (2:3.28.4-0ubuntu0.16.04.13) ...\n",
      "Selecting previously unselected package libnss3:amd64.\n",
      "Preparing to unpack .../libnss3_2%3a3.28.4-0ubuntu0.16.04.13_amd64.deb ...\n",
      "Unpacking libnss3:amd64 (2:3.28.4-0ubuntu0.16.04.13) ...\n",
      "Selecting previously unselected package libpcsclite1:amd64.\n",
      "Preparing to unpack .../libpcsclite1_1.8.14-1ubuntu1.16.04.1_amd64.deb ...\n",
      "Unpacking libpcsclite1:amd64 (1.8.14-1ubuntu1.16.04.1) ...\n",
      "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
      "Preparing to unpack .../openjdk-8-jre-headless_8u265-b01-0ubuntu2~16.04_amd64.deb ...\n",
      "Unpacking openjdk-8-jre-headless:amd64 (8u265-b01-0ubuntu2~16.04) ...\n",
      "Selecting previously unselected package default-jre-headless.\n",
      "Preparing to unpack .../default-jre-headless_2%3a1.8-56ubuntu2_amd64.deb ...\n",
      "Unpacking default-jre-headless (2:1.8-56ubuntu2) ...\n",
      "Selecting previously unselected package ca-certificates-java.\n",
      "Preparing to unpack .../ca-certificates-java_20160321ubuntu1_all.deb ...\n",
      "Unpacking ca-certificates-java (20160321ubuntu1) ...\n",
      "Selecting previously unselected package libasound2-data.\n",
      "Preparing to unpack .../libasound2-data_1.1.0-0ubuntu1_all.deb ...\n",
      "Unpacking libasound2-data (1.1.0-0ubuntu1) ...\n",
      "Selecting previously unselected package libasound2:amd64.\n",
      "Preparing to unpack .../libasound2_1.1.0-0ubuntu1_amd64.deb ...\n",
      "Unpacking libasound2:amd64 (1.1.0-0ubuntu1) ...\n",
      "Selecting previously unselected package libgif7:amd64.\n",
      "Preparing to unpack .../libgif7_5.1.4-0.3~16.04.1_amd64.deb ...\n",
      "Unpacking libgif7:amd64 (5.1.4-0.3~16.04.1) ...\n",
      "Selecting previously unselected package libflac8:amd64.\n",
      "Preparing to unpack .../libflac8_1.3.1-4_amd64.deb ...\n",
      "Unpacking libflac8:amd64 (1.3.1-4) ...\n",
      "Selecting previously unselected package libsndfile1:amd64.\n",
      "Preparing to unpack .../libsndfile1_1.0.25-10ubuntu0.16.04.2_amd64.deb ...\n",
      "Unpacking libsndfile1:amd64 (1.0.25-10ubuntu0.16.04.2) ...\n",
      "Selecting previously unselected package libpulse0:amd64.\n",
      "Preparing to unpack .../libpulse0_1%3a8.0-0ubuntu3.12_amd64.deb ...\n",
      "Unpacking libpulse0:amd64 (1:8.0-0ubuntu3.12) ...\n",
      "Selecting previously unselected package openjdk-8-jre:amd64.\n",
      "Preparing to unpack .../openjdk-8-jre_8u265-b01-0ubuntu2~16.04_amd64.deb ...\n",
      "Unpacking openjdk-8-jre:amd64 (8u265-b01-0ubuntu2~16.04) ...\n",
      "Selecting previously unselected package default-jre.\n",
      "Preparing to unpack .../default-jre_2%3a1.8-56ubuntu2_amd64.deb ...\n",
      "Unpacking default-jre (2:1.8-56ubuntu2) ...\n",
      "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
      "Preparing to unpack .../openjdk-8-jdk-headless_8u265-b01-0ubuntu2~16.04_amd64.deb ...\n",
      "Unpacking openjdk-8-jdk-headless:amd64 (8u265-b01-0ubuntu2~16.04) ...\n",
      "Selecting previously unselected package default-jdk-headless.\n",
      "Preparing to unpack .../default-jdk-headless_2%3a1.8-56ubuntu2_amd64.deb ...\n",
      "Unpacking default-jdk-headless (2:1.8-56ubuntu2) ...\n",
      "Selecting previously unselected package openjdk-8-jdk:amd64.\n",
      "Preparing to unpack .../openjdk-8-jdk_8u265-b01-0ubuntu2~16.04_amd64.deb ...\n",
      "Unpacking openjdk-8-jdk:amd64 (8u265-b01-0ubuntu2~16.04) ...\n",
      "Selecting previously unselected package default-jdk.\n",
      "Preparing to unpack .../default-jdk_2%3a1.8-56ubuntu2_amd64.deb ...\n",
      "Unpacking default-jdk (2:1.8-56ubuntu2) ...\n",
      "Processing triggers for libc-bin (2.23-0ubuntu11.2) ...\n",
      "Processing triggers for ca-certificates (20190110~16.04.1) ...\n",
      "Updating certificates in /etc/ssl/certs...\n",
      "0 added, 0 removed; done.\n",
      "Running hooks in /etc/ca-certificates/update.d...\n",
      "done.\n",
      "Processing triggers for mime-support (3.59ubuntu1) ...\n",
      "Setting up libasyncns0:amd64 (0.8-5build1) ...\n",
      "Setting up libxtst6:amd64 (2:1.2.2-1) ...\n",
      "Setting up java-common (0.56ubuntu2) ...\n",
      "Setting up liblcms2-2:amd64 (2.6-3ubuntu2.1) ...\n",
      "Setting up libnspr4:amd64 (2:4.13.1-0ubuntu0.16.04.1) ...\n",
      "Setting up libpcsclite1:amd64 (1.8.14-1ubuntu1.16.04.1) ...\n",
      "Setting up libasound2-data (1.1.0-0ubuntu1) ...\n",
      "Setting up libasound2:amd64 (1.1.0-0ubuntu1) ...\n",
      "Setting up libgif7:amd64 (5.1.4-0.3~16.04.1) ...\n",
      "Setting up libflac8:amd64 (1.3.1-4) ...\n",
      "Setting up libsndfile1:amd64 (1.0.25-10ubuntu0.16.04.2) ...\n",
      "Setting up libpulse0:amd64 (1:8.0-0ubuntu3.12) ...\n",
      "Setting up libnss3-nssdb (2:3.28.4-0ubuntu0.16.04.13) ...\n",
      "Setting up libnss3:amd64 (2:3.28.4-0ubuntu0.16.04.13) ...\n",
      "Setting up openjdk-8-jre-headless:amd64 (8u265-b01-0ubuntu2~16.04) ...\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/rmid to provide /usr/bin/rmid (rmid) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java to provide /usr/bin/java (java) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/keytool to provide /usr/bin/keytool (keytool) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/jjs to provide /usr/bin/jjs (jjs) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/pack200 to provide /usr/bin/pack200 (pack200) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/rmiregistry to provide /usr/bin/rmiregistry (rmiregistry) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/unpack200 to provide /usr/bin/unpack200 (unpack200) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jexec to provide /usr/bin/jexec (jexec) in auto mode\n",
      "Setting up default-jre-headless (2:1.8-56ubuntu2) ...\n",
      "Setting up openjdk-8-jre:amd64 (8u265-b01-0ubuntu2~16.04) ...\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/policytool to provide /usr/bin/policytool (policytool) in auto mode\n",
      "Setting up default-jre (2:1.8-56ubuntu2) ...\n",
      "Setting up openjdk-8-jdk-headless:amd64 (8u265-b01-0ubuntu2~16.04) ...\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jdeps to provide /usr/bin/jdeps (jdeps) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jinfo to provide /usr/bin/jinfo (jinfo) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jstat to provide /usr/bin/jstat (jstat) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javadoc to provide /usr/bin/javadoc (javadoc) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jps to provide /usr/bin/jps (jps) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jstack to provide /usr/bin/jstack (jstack) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jrunscript to provide /usr/bin/jrunscript (jrunscript) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javac to provide /usr/bin/javac (javac) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javap to provide /usr/bin/javap (javap) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jar to provide /usr/bin/jar (jar) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jarsigner to provide /usr/bin/jarsigner (jarsigner) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/rmic to provide /usr/bin/rmic (rmic) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jstatd to provide /usr/bin/jstatd (jstatd) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jdb to provide /usr/bin/jdb (jdb) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/serialver to provide /usr/bin/serialver (serialver) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jcmd to provide /usr/bin/jcmd (jcmd) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jmap to provide /usr/bin/jmap (jmap) in auto mode\n",
      "Setting up default-jdk-headless (2:1.8-56ubuntu2) ...\n",
      "Setting up openjdk-8-jdk:amd64 (8u265-b01-0ubuntu2~16.04) ...\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/appletviewer to provide /usr/bin/appletviewer (appletviewer) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jconsole to provide /usr/bin/jconsole (jconsole) in auto mode\n",
      "Setting up default-jdk (2:1.8-56ubuntu2) ...\n",
      "Setting up ca-certificates-java (20160321ubuntu1) ...\n",
      "Adding debian:thawte_Primary_Root_CA.pem\n",
      "Adding debian:Certplus_Class_2_Primary_CA.pem\n",
      "Adding debian:Chambers_of_Commerce_Root_-_2008.pem\n",
      "Adding debian:DigiCert_Assured_ID_Root_G2.pem\n",
      "Adding debian:QuoVadis_Root_CA_3.pem\n",
      "Adding debian:IdenTrust_Commercial_Root_CA_1.pem\n",
      "Adding debian:E-Tugra_Certification_Authority.pem\n",
      "Adding debian:CA_Disig_Root_R2.pem\n",
      "Adding debian:NetLock_Arany_=Class_Gold=_Ftanstvny.pem\n",
      "Adding debian:QuoVadis_Root_CA.pem\n",
      "Adding debian:TUBITAK_Kamu_SM_SSL_Kok_Sertifikasi_-_Surum_1.pem\n",
      "Adding debian:XRamp_Global_CA_Root.pem\n",
      "Adding debian:SZAFIR_ROOT_CA2.pem\n",
      "Adding debian:Security_Communication_Root_CA.pem\n",
      "Adding debian:Hongkong_Post_Root_CA_1.pem\n",
      "Adding debian:AC_RAIZ_FNMT-RCM.pem\n",
      "Adding debian:D-TRUST_Root_Class_3_CA_2_EV_2009.pem\n",
      "Adding debian:Trustis_FPS_Root_CA.pem\n",
      "Adding debian:IdenTrust_Public_Sector_Root_CA_1.pem\n",
      "Adding debian:DigiCert_Global_Root_G3.pem\n",
      "Adding debian:VeriSign_Class_3_Public_Primary_Certification_Authority_-_G5.pem\n",
      "Adding debian:Certigna.pem\n",
      "Adding debian:DigiCert_Assured_ID_Root_CA.pem\n",
      "Adding debian:AffirmTrust_Commercial.pem\n",
      "Adding debian:D-TRUST_Root_Class_3_CA_2_2009.pem\n",
      "Adding debian:Global_Chambersign_Root_-_2008.pem\n",
      "Adding debian:Amazon_Root_CA_2.pem\n",
      "Adding debian:TeliaSonera_Root_CA_v1.pem\n",
      "Adding debian:TrustCor_RootCert_CA-1.pem\n",
      "Adding debian:SwissSign_Gold_CA_-_G2.pem\n",
      "Adding debian:Amazon_Root_CA_3.pem\n",
      "Adding debian:Microsec_e-Szigno_Root_CA_2009.pem\n",
      "Adding debian:EC-ACC.pem\n",
      "Adding debian:Entrust.net_Premium_2048_Secure_Server_CA.pem\n",
      "Adding debian:COMODO_RSA_Certification_Authority.pem\n",
      "Adding debian:DigiCert_High_Assurance_EV_Root_CA.pem\n",
      "Adding debian:GDCA_TrustAUTH_R5_ROOT.pem\n",
      "Adding debian:T-TeleSec_GlobalRoot_Class_2.pem\n",
      "Adding debian:Go_Daddy_Root_Certificate_Authority_-_G2.pem\n",
      "Adding debian:Certum_Trusted_Network_CA_2.pem\n",
      "Adding debian:Baltimore_CyberTrust_Root.pem\n",
      "Adding debian:DigiCert_Trusted_Root_G4.pem\n",
      "Adding debian:USERTrust_ECC_Certification_Authority.pem\n",
      "Adding debian:QuoVadis_Root_CA_2_G3.pem\n",
      "Adding debian:SwissSign_Silver_CA_-_G2.pem\n",
      "Adding debian:VeriSign_Class_3_Public_Primary_Certification_Authority_-_G4.pem\n",
      "Adding debian:SSL.com_Root_Certification_Authority_ECC.pem\n",
      "Adding debian:Autoridad_de_Certificacion_Firmaprofesional_CIF_A62634068.pem\n",
      "Adding debian:Entrust_Root_Certification_Authority_-_G2.pem\n",
      "Adding debian:GeoTrust_Primary_Certification_Authority.pem\n",
      "Adding debian:DST_Root_CA_X3.pem\n",
      "Adding debian:COMODO_ECC_Certification_Authority.pem\n",
      "Adding debian:GlobalSign_Root_CA_-_R6.pem\n",
      "Adding debian:VeriSign_Universal_Root_Certification_Authority.pem\n",
      "Adding debian:TWCA_Root_Certification_Authority.pem\n",
      "Adding debian:Hellenic_Academic_and_Research_Institutions_ECC_RootCA_2015.pem\n",
      "Adding debian:GeoTrust_Global_CA.pem\n",
      "Adding debian:Cybertrust_Global_Root.pem\n",
      "Adding debian:AffirmTrust_Networking.pem\n",
      "Adding debian:COMODO_Certification_Authority.pem\n",
      "Adding debian:Deutsche_Telekom_Root_CA_2.pem\n",
      "Adding debian:thawte_Primary_Root_CA_-_G2.pem\n",
      "Adding debian:ISRG_Root_X1.pem\n",
      "Adding debian:GeoTrust_Universal_CA.pem\n",
      "Adding debian:Staat_der_Nederlanden_EV_Root_CA.pem\n",
      "Adding debian:Network_Solutions_Certificate_Authority.pem\n",
      "Adding debian:Taiwan_GRCA.pem\n",
      "Adding debian:Amazon_Root_CA_4.pem\n",
      "Adding debian:Go_Daddy_Class_2_CA.pem\n",
      "Adding debian:AffirmTrust_Premium.pem\n",
      "Adding debian:Hellenic_Academic_and_Research_Institutions_RootCA_2011.pem\n",
      "Adding debian:ACCVRAIZ1.pem\n",
      "Adding debian:TrustCor_ECA-1.pem\n",
      "Adding debian:USERTrust_RSA_Certification_Authority.pem\n",
      "Adding debian:thawte_Primary_Root_CA_-_G3.pem\n",
      "Adding debian:GeoTrust_Primary_Certification_Authority_-_G3.pem\n",
      "Adding debian:Staat_der_Nederlanden_Root_CA_-_G3.pem\n",
      "Adding debian:TWCA_Global_Root_CA.pem\n",
      "Adding debian:DigiCert_Global_Root_G2.pem\n",
      "Adding debian:GeoTrust_Primary_Certification_Authority_-_G2.pem\n",
      "Adding debian:Izenpe.com.pem\n",
      "Adding debian:ePKI_Root_Certification_Authority.pem\n",
      "Adding debian:Sonera_Class_2_Root_CA.pem\n",
      "Adding debian:QuoVadis_Root_CA_3_G3.pem\n",
      "Adding debian:OISTE_WISeKey_Global_Root_GA_CA.pem\n",
      "Adding debian:SSL.com_Root_Certification_Authority_RSA.pem\n",
      "Adding debian:Security_Communication_RootCA2.pem\n",
      "Adding debian:Starfield_Class_2_CA.pem\n",
      "Adding debian:LuxTrust_Global_Root_2.pem\n",
      "Adding debian:SecureTrust_CA.pem\n",
      "Adding debian:Certum_Trusted_Network_CA.pem\n",
      "Adding debian:Amazon_Root_CA_1.pem\n",
      "Adding debian:SecureSign_RootCA11.pem\n",
      "Adding debian:TrustCor_RootCert_CA-2.pem\n",
      "Adding debian:DigiCert_Global_Root_CA.pem\n",
      "Adding debian:SSL.com_EV_Root_Certification_Authority_ECC.pem\n",
      "Adding debian:OISTE_WISeKey_Global_Root_GB_CA.pem\n",
      "Adding debian:Secure_Global_CA.pem\n",
      "Adding debian:AffirmTrust_Premium_ECC.pem\n",
      "Adding debian:GlobalSign_Root_CA_-_R3.pem\n",
      "Adding debian:Buypass_Class_3_Root_CA.pem\n",
      "Adding debian:Comodo_AAA_Services_root.pem\n",
      "Adding debian:Certinomis_-_Root_CA.pem\n",
      "Adding debian:Verisign_Class_3_Public_Primary_Certification_Authority_-_G3.pem\n",
      "Adding debian:Starfield_Root_Certificate_Authority_-_G2.pem\n",
      "Adding debian:QuoVadis_Root_CA_2.pem\n",
      "Adding debian:Buypass_Class_2_Root_CA.pem\n",
      "Adding debian:Actalis_Authentication_Root_CA.pem\n",
      "Adding debian:QuoVadis_Root_CA_1_G3.pem\n",
      "Adding debian:DigiCert_Assured_ID_Root_G3.pem\n",
      "Adding debian:Entrust_Root_Certification_Authority_-_EC1.pem\n",
      "Adding debian:EE_Certification_Centre_Root_CA.pem\n",
      "Adding debian:OISTE_WISeKey_Global_Root_GC_CA.pem\n",
      "Adding debian:T-TeleSec_GlobalRoot_Class_3.pem\n",
      "Adding debian:GlobalSign_ECC_Root_CA_-_R5.pem\n",
      "Adding debian:Starfield_Services_Root_Certificate_Authority_-_G2.pem\n",
      "Adding debian:CFCA_EV_ROOT.pem\n",
      "Adding debian:Hellenic_Academic_and_Research_Institutions_RootCA_2015.pem\n",
      "Adding debian:Entrust_Root_Certification_Authority.pem\n",
      "Adding debian:GlobalSign_Root_CA.pem\n",
      "Adding debian:certSIGN_ROOT_CA.pem\n",
      "Adding debian:Atos_TrustedRoot_2011.pem\n",
      "Adding debian:Staat_der_Nederlanden_Root_CA_-_G2.pem\n",
      "Adding debian:GlobalSign_ECC_Root_CA_-_R4.pem\n",
      "Adding debian:SSL.com_EV_Root_Certification_Authority_RSA_R2.pem\n",
      "Adding debian:GlobalSign_Root_CA_-_R2.pem\n",
      "Adding debian:GeoTrust_Universal_CA_2.pem\n",
      "done.\n",
      "Processing triggers for libc-bin (2.23-0ubuntu11.2) ...\n",
      "Processing triggers for ca-certificates (20190110~16.04.1) ...\n",
      "Updating certificates in /etc/ssl/certs...\n",
      "0 added, 0 removed; done.\n",
      "Running hooks in /etc/ca-certificates/update.d...\n",
      "\n",
      "done.\n",
      "done.\n",
      "Removing intermediate container 076974884a35\n",
      " ---> 26fc46725d87\n",
      "Step 9/13 : RUN rm -rf /var/lib/apt/lists/*\n",
      " ---> Running in 2410d3aa22a0\n",
      "Removing intermediate container 2410d3aa22a0\n",
      " ---> 18e1c6168f09\n",
      "Step 10/13 : COPY code/custom_lightgbm_inference-0.1.0.tar.gz /custom_lightgbm_inference-0.1.0.tar.gz\n",
      " ---> 4025123f2213\n",
      "Step 11/13 : RUN ${PIP} install --no-cache --upgrade         /custom_lightgbm_inference-0.1.0.tar.gz &&     rm /custom_lightgbm_inference-0.1.0.tar.gz\n",
      " ---> Running in dd3a733743ce\n",
      "Processing /custom_lightgbm_inference-0.1.0.tar.gz\n",
      "Collecting sagemaker-inference==1.3.0\n",
      "  Downloading sagemaker_inference-1.3.0.tar.gz (17 kB)\n",
      "Collecting multi-model-server==1.1.2\n",
      "  Downloading multi_model_server-1.1.2-py2.py3-none-any.whl (4.9 MB)\n",
      "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/site-packages (from sagemaker-inference==1.3.0->custom-lightgbm-inference==0.1.0) (1.14.5)\n",
      "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/site-packages (from sagemaker-inference==1.3.0->custom-lightgbm-inference==0.1.0) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: typing in /usr/local/lib/python3.6/site-packages (from sagemaker-inference==1.3.0->custom-lightgbm-inference==0.1.0) (3.7.4.3)\n",
      "Requirement already satisfied, skipping upgrade: psutil in /usr/local/lib/python3.6/site-packages (from sagemaker-inference==1.3.0->custom-lightgbm-inference==0.1.0) (5.7.2)\n",
      "Requirement already satisfied, skipping upgrade: retrying==1.3.3 in /usr/local/lib/python3.6/site-packages (from sagemaker-inference==1.3.0->custom-lightgbm-inference==0.1.0) (1.3.3)\n",
      "Collecting Pillow\n",
      "  Downloading Pillow-7.2.0-cp36-cp36m-manylinux1_x86_64.whl (2.2 MB)\n",
      "Collecting future\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\n",
      "Collecting model-archiver\n",
      "  Downloading model_archiver-1.0.3-py2.py3-none-any.whl (20 kB)\n",
      "Collecting enum-compat\n",
      "  Downloading enum_compat-0.0.3-py3-none-any.whl (1.3 kB)\n",
      "Using legacy setup.py install for custom-lightgbm-inference, since package 'wheel' is not installed.\n",
      "Using legacy setup.py install for sagemaker-inference, since package 'wheel' is not installed.\n",
      "Using legacy setup.py install for future, since package 'wheel' is not installed.\n",
      "Installing collected packages: sagemaker-inference, Pillow, future, enum-compat, model-archiver, multi-model-server, custom-lightgbm-inference\n",
      "    Running setup.py install for sagemaker-inference: started\n",
      "    Running setup.py install for sagemaker-inference: finished with status 'done'\n",
      "    Running setup.py install for future: started\n",
      "    Running setup.py install for future: finished with status 'done'\n",
      "    Running setup.py install for custom-lightgbm-inference: started\n",
      "    Running setup.py install for custom-lightgbm-inference: finished with status 'done'\n",
      "Successfully installed Pillow-7.2.0 custom-lightgbm-inference-0.1.0 enum-compat-0.0.3 future-0.18.2 model-archiver-1.0.3 multi-model-server-1.1.2 sagemaker-inference-1.3.0\n",
      "\u001b[91mWARNING: You are using pip version 20.1.1; however, version 20.2.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.6 -m pip install --upgrade pip' command.\n",
      "\u001b[0mRemoving intermediate container dd3a733743ce\n",
      " ---> 2bcf6c358eba\n",
      "Step 12/13 : ENV SM_MODEL_DIR /opt/ml/model\n",
      " ---> Running in a557254dcb4c\n",
      "Removing intermediate container a557254dcb4c\n",
      " ---> 2fb2c6160e52\n",
      "Step 13/13 : ENV CODE_DIR /opt/ml/code\n",
      " ---> Running in ec7cbc182647\n",
      "Removing intermediate container ec7cbc182647\n",
      " ---> 49cb0e6f8d80\n",
      "Successfully built 49cb0e6f8d80\n",
      "Successfully tagged iris_model:1.0\n"
     ]
    }
   ],
   "source": [
    "!docker build -f docker/Dockerfile -t iris_model:1.0 ./docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building docker image...\n",
      "Sending build context to Docker daemon   7.68kB\n",
      "Step 1/13 : FROM sagemaker-training-containers/framework-container:latest\n",
      " ---> 6e6a47cf0f36\n",
      "Step 2/13 : ARG PYTHON=python3\n",
      " ---> Using cache\n",
      " ---> a8cb49fa3ec4\n",
      "Step 3/13 : ARG PYTHON_PIP=python3-pip\n",
      " ---> Using cache\n",
      " ---> 7096781dc9d8\n",
      "Step 4/13 : ARG PIP=pip3\n",
      " ---> Using cache\n",
      " ---> 30b0cfbde1dc\n",
      "Step 5/13 : ARG PYTHON_VERSION=3.6.6\n",
      " ---> Using cache\n",
      " ---> 65862c7be643\n",
      "Step 6/13 : LABEL com.amazonaws.sagemaker.capabilities.multi-models=false\n",
      " ---> Using cache\n",
      " ---> 3c6656952914\n",
      "Step 7/13 : LABEL com.amazonaws.sagemaker.capabilities.accept-bind-to-port=true\n",
      " ---> Using cache\n",
      " ---> 8c6ac00dd42a\n",
      "Step 8/13 : RUN apt-get update -y && apt-get -y install --no-install-recommends default-jdk\n",
      " ---> Using cache\n",
      " ---> 26fc46725d87\n",
      "Step 9/13 : RUN rm -rf /var/lib/apt/lists/*\n",
      " ---> Using cache\n",
      " ---> 18e1c6168f09\n",
      "Step 10/13 : COPY code/custom_lightgbm_inference-0.1.0.tar.gz /custom_lightgbm_inference-0.1.0.tar.gz\n",
      " ---> Using cache\n",
      " ---> 4025123f2213\n",
      "Step 11/13 : RUN ${PIP} install --no-cache --upgrade         /custom_lightgbm_inference-0.1.0.tar.gz &&     rm /custom_lightgbm_inference-0.1.0.tar.gz\n",
      " ---> Using cache\n",
      " ---> 2bcf6c358eba\n",
      "Step 12/13 : ENV SM_MODEL_DIR /opt/ml/model\n",
      " ---> Using cache\n",
      " ---> 2fb2c6160e52\n",
      "Step 13/13 : ENV CODE_DIR /opt/ml/code\n",
      " ---> Using cache\n",
      " ---> 49cb0e6f8d80\n",
      "Successfully built 49cb0e6f8d80\n",
      "Successfully tagged iris-model:latest\n",
      "Tagging docker image...\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "{\n",
      "    \"repositories\": [\n",
      "        {\n",
      "            \"repositoryArn\": \"arn:aws:ecr:us-east-1:725879053979:repository/iris-model\",\n",
      "            \"registryId\": \"725879053979\",\n",
      "            \"repositoryName\": \"iris-model\",\n",
      "            \"repositoryUri\": \"725879053979.dkr.ecr.us-east-1.amazonaws.com/iris-model\",\n",
      "            \"createdAt\": 1587150018.0,\n",
      "            \"imageTagMutability\": \"MUTABLE\",\n",
      "            \"imageScanningConfiguration\": {\n",
      "                \"scanOnPush\": false\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Pushing docker image to ECR...\n",
      "The push refers to repository [725879053979.dkr.ecr.us-east-1.amazonaws.com/iris-model]\n",
      "\n",
      "\u001b[1B7b51ca13: Preparing \n",
      "\u001b[1B4729b798: Preparing \n",
      "\u001b[1Bc551178d: Preparing \n",
      "\u001b[1Bc863d801: Preparing \n",
      "\u001b[1B585566e5: Preparing \n",
      "\u001b[1B663eb2b4: Preparing \n",
      "\u001b[1Bf926688f: Preparing \n",
      "\u001b[1B65d61e4d: Preparing \n",
      "\u001b[1B5c2e68c7: Preparing \n",
      "\u001b[1B25865bc0: Preparing \n",
      "\u001b[1B4637480e: Preparing \n",
      "\u001b[1B7a0a3078: Preparing \n",
      "\u001b[1B490753a8: Preparing \n",
      "\u001b[11B863d801: Pushed   180.7MB/180MBMB3A\u001b[2K\u001b[14A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[14A\u001b[2K\u001b[13A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[11A\u001b[2K\u001b[14A\u001b[2K\u001b[11A\u001b[2K\u001b[14A\u001b[2K\u001b[11A\u001b[2K\u001b[14A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[14A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2Klatest: digest: sha256:9f92e4643d08c7e36244e8a91c003c82e63e614954e7ea1438123ce5751ec7c7 size: 3252\n"
     ]
    }
   ],
   "source": [
    "! scripts/build_and_push.sh $account_id $region $ecr_repository_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "container_image_uri = '725879053979.dkr.ecr.us-east-1.amazonaws.com/iris-model:latest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = 's3://sagemaker-us-east-1-725879053979/sagemaker-custom/data/iris_train.csv'\n",
    "test_config = 's3://sagemaker-us-east-1-725879053979/sagemaker-custom/data/iris_test.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = 's3://sagemaker-us-east-1-725879053979/sagemaker-custom/code/sourcedir.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import json\n",
    "\n",
    "# JSON encode hyperparameters.\n",
    "def json_encode_hyperparameters(hyperparameters):\n",
    "    return {str(k): json.dumps(v) for (k, v) in hyperparameters.items()}\n",
    "\n",
    "hyperparameters = json_encode_hyperparameters({\n",
    "    \"sagemaker_program\": \"train.py\",\n",
    "    \"sagemaker_submit_directory\": sources})\n",
    "#     \"hp1\": \"value1\",\n",
    "#     \"hp2\": 300,\n",
    "#     \"hp3\": 0.001}\n",
    "# )\n",
    "\n",
    "estimator = sagemaker.estimator.Estimator(container_image_uri,\n",
    "                                    role,\n",
    "                                    train_instance_count=1, \n",
    "                                    train_instance_type='local',\n",
    "                                    base_job_name='iris',\n",
    "                                    hyperparameters=hyperparameters,\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker:'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "WARNING:sagemaker:'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tmpubddauzb_algo-1-l8422_1 ... \n",
      "\u001b[1BAttaching to tmpubddauzb_algo-1-l8422_12mdone\u001b[0m\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m 2020-08-11 17:46:10,870 sagemaker-training-toolkit INFO     Imported framework custom_lightgbm_framework.training\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m 2020-08-11 17:46:10,872 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m 2020-08-11 17:46:10,885 custom_lightgbm_framework.training INFO     Invoking user training script.\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m 2020-08-11 17:46:11,038 sagemaker-training-toolkit INFO     Module train.py does not provide a setup.py. \n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m Generating setup.py\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m 2020-08-11 17:46:11,038 sagemaker-training-toolkit INFO     Generating setup.cfg\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m 2020-08-11 17:46:11,039 sagemaker-training-toolkit INFO     Generating MANIFEST.in\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m 2020-08-11 17:46:11,039 sagemaker-training-toolkit INFO     Installing module with the following command:\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m /usr/local/bin/python3.6 -m pip install . \n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m Processing /opt/ml/code\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m Using legacy setup.py install for train.py, since package 'wheel' is not installed.\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m Installing collected packages: train.py\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m     Running setup.py install for train.py ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m \u001b[?25hSuccessfully installed train.py-1.0.0\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m \u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.2 is available.\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m You should consider upgrading via the '/usr/local/bin/python3.6 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m 2020-08-11 17:46:12,449 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m 2020-08-11 17:46:12,465 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m 2020-08-11 17:46:12,480 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m 2020-08-11 17:46:12,493 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m \n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m Training Env:\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m \n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m {\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m         \"train\": \"/opt/ml/input/data/train\",\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m         \"validation\": \"/opt/ml/input/data/validation\"\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m     \"current_host\": \"algo-1-l8422\",\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m     \"framework_module\": \"custom_lightgbm_framework.training:main\",\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m     \"hosts\": [\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m         \"algo-1-l8422\"\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m     ],\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m     \"hyperparameters\": {},\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m         \"train\": {\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m         },\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m         \"validation\": {\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m         }\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m     \"job_name\": \"iris-2020-08-11-17-46-08-463\",\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m     \"master_hostname\": \"algo-1-l8422\",\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-725879053979/sagemaker-custom/code/sourcedir.tar.gz\",\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m     \"module_name\": \"train\",\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m     \"num_cpus\": 4,\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m         \"current_host\": \"algo-1-l8422\",\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m         \"hosts\": [\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m             \"algo-1-l8422\"\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m         ]\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m     \"user_entry_point\": \"train.py\"\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m }\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m \n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m Environment variables:\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m \n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m SM_HOSTS=[\"algo-1-l8422\"]\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m SM_HPS={}\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m SM_USER_ENTRY_POINT=train.py\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-l8422\",\"hosts\":[\"algo-1-l8422\"]}\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m SM_INPUT_DATA_CONFIG={\"train\":{\"TrainingInputMode\":\"File\"},\"validation\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m SM_CHANNELS=[\"train\",\"validation\"]\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m SM_CURRENT_HOST=algo-1-l8422\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m SM_MODULE_NAME=train\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m SM_FRAMEWORK_MODULE=custom_lightgbm_framework.training:main\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m SM_NUM_CPUS=4\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-725879053979/sagemaker-custom/code/sourcedir.tar.gz\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1-l8422\",\"framework_module\":\"custom_lightgbm_framework.training:main\",\"hosts\":[\"algo-1-l8422\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"TrainingInputMode\":\"File\"},\"validation\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"iris-2020-08-11-17-46-08-463\",\"log_level\":20,\"master_hostname\":\"algo-1-l8422\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-725879053979/sagemaker-custom/code/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-l8422\",\"hosts\":[\"algo-1-l8422\"]},\"user_entry_point\":\"train.py\"}\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m SM_USER_ARGS=[]\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m SM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m PYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python36.zip:/usr/local/lib/python3.6:/usr/local/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/site-packages\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m \n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m \n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m /usr/local/bin/python3.6 -m train\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m \n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m \n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m Training until validation scores don't improve for 5 rounds\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m [5]\t[validation_softmax]'s multi_logloss: 0.611145\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m [10]\t[validation_softmax]'s multi_logloss: 0.368221\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m [15]\t[validation_softmax]'s multi_logloss: 0.233036\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m [20]\t[validation_softmax]'s multi_logloss: 0.15482\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m [25]\t[validation_softmax]'s multi_logloss: 0.106663\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m [30]\t[validation_softmax]'s multi_logloss: 0.0812475\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m [35]\t[validation_softmax]'s multi_logloss: 0.0675059\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m [40]\t[validation_softmax]'s multi_logloss: 0.0580658\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m [45]\t[validation_softmax]'s multi_logloss: 0.0525272\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m [50]\t[validation_softmax]'s multi_logloss: 0.0491583\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m [55]\t[validation_softmax]'s multi_logloss: 0.045847\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m [60]\t[validation_softmax]'s multi_logloss: 0.0435514\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m [65]\t[validation_softmax]'s multi_logloss: 0.0422592\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m [70]\t[validation_softmax]'s multi_logloss: 0.0402636\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m [75]\t[validation_softmax]'s multi_logloss: 0.0393276\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m [80]\t[validation_softmax]'s multi_logloss: 0.0383856\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m [85]\t[validation_softmax]'s multi_logloss: 0.0365954\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m [90]\t[validation_softmax]'s multi_logloss: 0.0353582\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m [95]\t[validation_softmax]'s multi_logloss: 0.0345235\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m [100]\t[validation_softmax]'s multi_logloss: 0.0338347\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m Did not meet early stopping. Best iteration is:\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m [99]\t[validation_softmax]'s multi_logloss: 0.0334109\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m [F1 score] 0.9696969696969697\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m Saving the model.\n",
      "\u001b[36malgo-1-l8422_1  |\u001b[0m 2020-08-11 17:46:13,477 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "\u001b[36mtmpubddauzb_algo-1-l8422_1 exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({'train': train_config, 'validation': test_config })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker:Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fa2a256ef60>: Failed to establish a new connection: [Errno 111] Connection refused',)': /ping\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fa2a2138550>: Failed to establish a new connection: [Errno 111] Connection refused',)': /ping\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fa2a256e438>: Failed to establish a new connection: [Errno 111] Connection refused',)': /ping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attaching to tmp9g6c9zke_algo-1-5r1gr_1\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m Running handler service: custom_lightgbm_inference.handler\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m Warning: Calling MMS with mxnet-model-server. Please move to multi-model-server.\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m 2020-08-11 17:47:12,843 [INFO ] main com.amazonaws.ml.mms.ModelServer - \n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m MMS Home: /usr/local/lib/python3.6/site-packages\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m Current directory: /\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m Temp directory: /tmp\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m Number of GPUs: 0\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m Number of CPUs: 4\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m Max heap size: 3566 M\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m Python executable: /usr/local/bin/python3.6\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m Config file: /etc/sagemaker-mms.properties\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m Inference address: http://0.0.0.0:8080\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m Management address: http://0.0.0.0:8080\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m Model Store: /.sagemaker/mms/models\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m Initial Models: ALL\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m Log dir: /logs\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m Metrics dir: /logs\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m Netty threads: 0\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m Netty client threads: 0\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m Default workers per model: 4\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m Blacklist Regex: N/A\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m Maximum Response Size: 6553500\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m Maximum Request Size: 6553500\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m Preload model: false\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m Prefer direct buffer: false\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m 2020-08-11 17:47:12,945 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-9000-model\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m 2020-08-11 17:47:13,063 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - model_service_worker started with args: --sock-type unix --sock-name /tmp/.mms.sock.9000 --handler custom_lightgbm_inference.handler --model-path /.sagemaker/mms/models/model --model-name model --preload-model false --tmp-dir /tmp\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m 2020-08-11 17:47:13,064 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /tmp/.mms.sock.9000\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m 2020-08-11 17:47:13,065 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID] 32\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m 2020-08-11 17:47:13,065 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MMS worker started.\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m 2020-08-11 17:47:13,065 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.6\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m 2020-08-11 17:47:13,066 [INFO ] main com.amazonaws.ml.mms.wlm.ModelManager - Model model loaded.\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m 2020-08-11 17:47:13,072 [INFO ] main com.amazonaws.ml.mms.ModelServer - Initialize Inference server with: EpollServerSocketChannel.\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m 2020-08-11 17:47:13,083 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /tmp/.mms.sock.9000\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m 2020-08-11 17:47:13,083 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /tmp/.mms.sock.9000\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m 2020-08-11 17:47:13,083 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /tmp/.mms.sock.9000\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m 2020-08-11 17:47:13,083 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /tmp/.mms.sock.9000\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m 2020-08-11 17:47:13,156 [INFO ] main com.amazonaws.ml.mms.ModelServer - Inference API bind to: http://0.0.0.0:8080\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m 2020-08-11 17:47:13,161 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /tmp/.mms.sock.9000.\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m 2020-08-11 17:47:13,162 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /tmp/.mms.sock.9000.\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m Model server started.\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m 2020-08-11 17:47:13,164 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /tmp/.mms.sock.9000.\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m 2020-08-11 17:47:13,166 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /tmp/.mms.sock.9000.\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m 2020-08-11 17:47:13,174 [WARN ] pool-2-thread-1 com.amazonaws.ml.mms.metrics.MetricCollector - worker pid is not available yet.\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m 2020-08-11 17:47:14,318 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242acfffe120002-0000000f-00000001-0e091abd5c533d43-feb707c0\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m 2020-08-11 17:47:14,322 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242acfffe120002-0000000f-00000004-7d225abd5c533d43-221c7b30\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m 2020-08-11 17:47:14,328 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242acfffe120002-0000000f-00000000-be961abd5c533d43-3ec68b30\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m 2020-08-11 17:47:14,330 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 1081\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m 2020-08-11 17:47:14,330 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 1081\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m 2020-08-11 17:47:14,330 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 1085\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m 2020-08-11 17:47:14,332 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-3\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m 2020-08-11 17:47:14,333 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-1\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m 2020-08-11 17:47:14,333 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-4\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m 2020-08-11 17:47:14,334 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 1085\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m 2020-08-11 17:47:14,335 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-2\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m 2020-08-11 17:47:14,333 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242acfffe120002-0000000f-00000003-d9b29abd5c533d43-55ad907e\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m 2020-08-11 17:47:15,507 [INFO ] pool-1-thread-6 ACCESS_LOG - /172.18.0.1:50736 \"GET /ping HTTP/1.1\" 200 12\n",
      "!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(initial_instance_count=1,\n",
    "                 instance_type='local',\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m 2020-08-11 17:56:20,175 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 1\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m 2020-08-11 17:56:20,176 [INFO ] W-9000-model ACCESS_LOG - /172.18.0.1:50784 \"POST /invocations HTTP/1.1\" 200 3\n",
      "\n",
      "RESULT: 1.0 == 1.0 ? True\n",
      "\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m 2020-08-11 17:56:20,181 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 1\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m 2020-08-11 17:56:20,182 [INFO ] W-9000-model ACCESS_LOG - /172.18.0.1:50784 \"POST /invocations HTTP/1.1\" 200 2\n",
      "\n",
      "RESULT: 0.0 == 0.0 ? True\n",
      "\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m 2020-08-11 17:56:20,185 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 1\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m 2020-08-11 17:56:20,185 [INFO ] W-9000-model ACCESS_LOG - /172.18.0.1:50784 \"POST /invocations HTTP/1.1\" 200 2\n",
      "\n",
      "RESULT: 1.0 == 1.0 ? True\n",
      "\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m 2020-08-11 17:56:20,189 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 1\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m 2020-08-11 17:56:20,189 [INFO ] W-9000-model ACCESS_LOG - /172.18.0.1:50784 \"POST /invocations HTTP/1.1\" 200 2\n",
      "\n",
      "RESULT: 1.0 == 1.0 ? True\n",
      "\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m 2020-08-11 17:56:20,193 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 1\n",
      "\u001b[36malgo-1-5r1gr_1  |\u001b[0m 2020-08-11 17:56:20,193 [INFO ] W-9000-model ACCESS_LOG - /172.18.0.1:50784 \"POST /invocations HTTP/1.1\" 200 2\n",
      "\n",
      "RESULT: 0.0 == 0.0 ? True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from sagemaker.predictor import csv_serializer, csv_deserializer\n",
    "\n",
    "# configure the predictor to do everything for us\n",
    "predictor.content_type = 'text/csv'\n",
    "predictor.accept = 'text/csv'\n",
    "predictor.serializer = csv_serializer\n",
    "predictor.deserializer = None\n",
    "\n",
    "# load the testing data from the validation csv\n",
    "validation = pd.read_csv('../0_custom_train/notebook/data/iris_test.csv', header=None)\n",
    "idx = random.randint(0,len(validation)-5)\n",
    "req = validation.iloc[idx:idx+5].values\n",
    "\n",
    "# cut a sample with 5 lines from our dataset and then split the label from the features.\n",
    "X = req[:,0:-1].tolist()\n",
    "y = req[:,-1].tolist()\n",
    "\n",
    "# call the local endpoint\n",
    "for features,label in zip(X,y):\n",
    "    prediction = float(predictor.predict(features).decode('utf-8').strip())\n",
    "\n",
    "    # compare the results\n",
    "    print(\"\\nRESULT: {} == {} ? {}\\n\".format( label, prediction, label == prediction ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look open source implementations of a few SageMaker containers:\n",
    "\n",
    "https://github.com/aws/sagemaker-scikit-learn-container\n",
    "\n",
    "https://github.com/aws/sagemaker-xgboost-container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Now that we have the algorithm image we can run it to train/deploy a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then, we need to prepare the dataset\n",
    "You'll see that we're splitting the dataset into training and validation and also saving these two subsets of the dataset into csv files. These files will be then uploaded to an S3 Bucket and shared with SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iris_id</th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iris_id  sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
       "0      0.0                5.1               3.5                1.4   \n",
       "1      0.0                4.9               3.0                1.4   \n",
       "2      0.0                4.7               3.2                1.3   \n",
       "3      0.0                4.6               3.1                1.5   \n",
       "4      0.0                5.0               3.6                1.4   \n",
       "\n",
       "   petal width (cm)  \n",
       "0               0.2  \n",
       "1               0.2  \n",
       "2               0.2  \n",
       "3               0.2  \n",
       "4               0.2  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!rm -rf input\n",
    "!mkdir -p input/data/training\n",
    "!mkdir -p input/data/testing\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "dataset = np.insert(iris.data, 0, iris.target,axis=1)\n",
    "\n",
    "df = pd.DataFrame(data=dataset, columns=[\"iris_id\"] + iris.feature_names)\n",
    "X = df.iloc[:,1:]\n",
    "y = df.iloc[:,0]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "train_df = X_train.copy()\n",
    "train_df.insert(0, \"iris_id\", y_train)\n",
    "train_df.to_csv(\"input/data/training/training.csv\", sep=\",\", header=None, index=None)\n",
    "\n",
    "test_df = X_test.copy()\n",
    "test_df.insert(0, \"iris_id\", y_test)\n",
    "test_df.to_csv(\"input/data/testing/testing.csv\", sep=\",\", header=None, index=None)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Just a basic local test, using the local Docker daemon\n",
    "Here we will simulate SageMaker calling our docker container for training and serving. We'll do that using the built-in Docker Daemon of the Jupyter Notebook Instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf input/config && mkdir -p input/config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing input/config/hyperparameters.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile input/config/hyperparameters.json\n",
    "{\"max_depth\": 20, \"n_jobs\": 4, \"n_estimators\": 120}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing input/config/resourceconfig.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile input/config/resourceconfig.json\n",
    "{\"current_host\": \"localhost\", \"hosts\": [\"algo-1-kipw9\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing input/config/inputdataconfig.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile input/config/inputdataconfig.json\n",
    "{\"training\": {\"TrainingInputMode\": \"File\"}, \"testing\": {\"TrainingInputMode\": \"File\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "2020-07-28 15:53:41,354 sagemaker-training-toolkit INFO     Imported framework my_training\n",
      "CPU times: user 39.6 ms, sys: 13.9 ms, total: 53.5 ms\n",
      "Wall time: 2.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!rm -rf model/\n",
    "!mkdir -p model\n",
    "\n",
    "print( \"Training...\")\n",
    "!docker run --rm --name \"my_model\" \\\n",
    "    -v \"$PWD/model:/opt/ml/model\" \\\n",
    "    -v \"$PWD/input:/opt/ml/input\" iris_model:1.0 train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 This is the serving test. It simulates an Endpoint exposed by Sagemaker\n",
    "\n",
    "After you execute the next cell, this Jupyter notebook will freeze. A webservice will be exposed at the port 8080. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/serve\", line 5, in <module>\n",
      "    from custom_inference.cli.init_serve import main\n",
      "ModuleNotFoundError: No module named 'custom_inference'\n"
     ]
    }
   ],
   "source": [
    "!docker run --rm --name \"my_model\" \\\n",
    "    -p 8080:8080 \\\n",
    "    -v \"$PWD/model:/opt/ml/model\" \\\n",
    "    -v \"$PWD/input:/opt/ml/input\" iris_model:1.0 serve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> While the above cell is running, click here [TEST NOTEBOOK](02_Testing%20our%20local%20model%20server.ipynb) to run some tests.\n",
    "\n",
    "> After you finish the tests, press **STOP**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 3 - Integrated Test: Everything seems ok, now it's time to put all together\n",
    "\n",
    "We'll start by running a local **CodeBuild** test, to check the buildspec and also deploy this image into the container registry. Remember that SageMaker will only see images published to ECR.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "sts_client = boto3.client(\"sts\")\n",
    "session = boto3.session.Session()\n",
    "\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "region = session.region_name\n",
    "credentials = session.get_credentials()\n",
    "credentials = credentials.get_frozen_credentials()\n",
    "\n",
    "repo_name=\"iris-model\"\n",
    "image_tag=\"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo rm -rf tests && mkdir -p tests\n",
    "# !cp handler.py main.py train.py Dockerfile buildspec.yml tests/\n",
    "!cp handler_service.py inference_handler.py serving.py training.py Dockerfile buildspec.yml tests/\n",
    "with open(\"tests/vars.env\", \"w\") as f:\n",
    "    f.write(\"AWS_ACCOUNT_ID=%s\\n\" % account_id)\n",
    "    f.write(\"IMAGE_TAG=%s\\n\" % image_tag)\n",
    "    f.write(\"IMAGE_REPO_NAME=%s\\n\" % repo_name)\n",
    "    f.write(\"AWS_DEFAULT_REGION=%s\\n\" % region)\n",
    "    f.write(\"AWS_ACCESS_KEY_ID=%s\\n\" % credentials.access_key)\n",
    "    f.write(\"AWS_SECRET_ACCESS_KEY=%s\\n\" % credentials.secret_key)\n",
    "    f.write(\"AWS_SESSION_TOKEN=%s\\n\" % credentials.token )\n",
    "    f.close()\n",
    "\n",
    "!cat tests/vars.env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build Command:\n",
      "\n",
      "docker run -it -v /var/run/docker.sock:/var/run/docker.sock -e \"IMAGE_NAME=samirsouza/aws-codebuild-standard:3.0\" -e \"ARTIFACTS=/home/ec2-user/SageMaker/tmp_ars/amazon-sagemaker-mlops-workshop/lab/01_CreateAlgorithmContainer/scikit_based/tests/output\" -e \"SOURCE=/home/ec2-user/SageMaker/tmp_ars/amazon-sagemaker-mlops-workshop/lab/01_CreateAlgorithmContainer/scikit_based/tests\" -v \"/home/ec2-user/SageMaker/tmp_ars/amazon-sagemaker-mlops-workshop/lab/01_CreateAlgorithmContainer/scikit_based/tests:/LocalBuild/envFile/\" -e \"ENV_VAR_FILE=vars.env\" -e \"AWS_CONFIGURATION=/home/ec2-user/.aws\" -e \"AWS_CLOUDWATCH_HOME=/opt/aws/apitools/mon\" -e \"AWS_PATH=/opt/aws\" -e \"AWS_AUTO_SCALING_HOME=/opt/aws/apitools/as\" -e \"AWS_ELB_HOME=/opt/aws/apitools/elb\" -e \"INITIATOR=ec2-user\" amazon/aws-codebuild-local:latest\n",
      "\n",
      "Removing agent-resources_build_1 ... \n",
      "Removing agent-resources_agent_1 ... \n",
      "\u001b[2BRemoving network agent-resources_defaultne\u001b[0m\n",
      "Removing volume agent-resources_source_volume\n",
      "Removing volume agent-resources_user_volume\n",
      "Creating network \"agent-resources_default\" with the default driver\n",
      "Creating volume \"agent-resources_source_volume\" with local driver\n",
      "Creating volume \"agent-resources_user_volume\" with local driver\n",
      "Creating agent-resources_agent_1 ... \n",
      "\u001b[1BCreating agent-resources_build_1 ... mdone\u001b[0m\n",
      "\u001b[1BAttaching to agent-resources_agent_1, agent-resources_build_1\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:42 Waiting for agent ping\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:43 Waiting for DOWNLOAD_SOURCE\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:44 Phase is DOWNLOAD_SOURCE\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:44 CODEBUILD_SRC_DIR=/codebuild/output/src145685821/src\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:44 YAML location is /codebuild/output/srcDownload/src/buildspec.yml\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:44 No commands found for phase name: install\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:44 Processing environment variables\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:44 Running command echo \"Specifying docker version in buildspec is deprecated. Using docker $DOCKER_VERSION .\"\n",
      "\u001b[36magent_1  |\u001b[0m Specifying docker version in buildspec is deprecated. Using docker 19.03.1 .\n",
      "\u001b[36magent_1  |\u001b[0m \n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:44 Moving to directory /codebuild/output/src145685821/src\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:44 Registering with agent\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:44 Phases found in YAML: 4\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:44  INSTALL: 0 commands\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:44  PRE_BUILD: 2 commands\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:44  BUILD: 4 commands\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:44  POST_BUILD: 6 commands\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:44 Phase complete: DOWNLOAD_SOURCE State: SUCCEEDED\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:44 Phase context status code:  Message: \n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:44 Entering phase INSTALL\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:44 Phase complete: INSTALL State: SUCCEEDED\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:44 Phase context status code:  Message: \n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:44 Entering phase PRE_BUILD\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:44 Running command echo Logging in to Amazon ECR...\n",
      "\u001b[36magent_1  |\u001b[0m Logging in to Amazon ECR...\n",
      "\u001b[36magent_1  |\u001b[0m \n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:44 Running command $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION)\n",
      "\u001b[36magent_1  |\u001b[0m WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "\u001b[36magent_1  |\u001b[0m WARNING! Your password will be stored unencrypted in /root/.docker/config.json.\n",
      "\u001b[36magent_1  |\u001b[0m Configure a credential helper to remove this warning. See\n",
      "\u001b[36magent_1  |\u001b[0m https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\u001b[36magent_1  |\u001b[0m \n",
      "\u001b[36magent_1  |\u001b[0m Login Succeeded\n",
      "\u001b[36magent_1  |\u001b[0m \n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:45 Phase complete: PRE_BUILD State: SUCCEEDED\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:45 Phase context status code:  Message: \n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:45 Entering phase BUILD\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:45 Running command echo Build started on `date`\n",
      "\u001b[36magent_1  |\u001b[0m Build started on Sun Jul 19 01:11:45 UTC 2020\n",
      "\u001b[36magent_1  |\u001b[0m \n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:45 Running command echo Building the Docker image...\n",
      "\u001b[36magent_1  |\u001b[0m Building the Docker image...\n",
      "\u001b[36magent_1  |\u001b[0m \n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:45 Running command docker build -t $IMAGE_REPO_NAME:$IMAGE_TAG .\n",
      "\u001b[36magent_1  |\u001b[0m Sending build context to Docker daemon  14.85kB\n",
      "\u001b[36magent_1  |\u001b[0m Step 1/22 : FROM python:3.7-buster\n",
      "\u001b[36magent_1  |\u001b[0m  ---> 014d597185ae\n",
      "\u001b[36magent_1  |\u001b[0m Step 2/22 : LABEL com.amazonaws.sagemaker.capabilities.multi-models=false\n",
      "\u001b[36magent_1  |\u001b[0m  ---> Using cache\n",
      "\u001b[36magent_1  |\u001b[0m  ---> c82281ba180f\n",
      "\u001b[36magent_1  |\u001b[0m Step 3/22 : LABEL com.amazonaws.sagemaker.capabilities.accept-bind-to-port=true\n",
      "\u001b[36magent_1  |\u001b[0m  ---> Using cache\n",
      "\u001b[36magent_1  |\u001b[0m  ---> 18c25a86e34c\n",
      "\u001b[36magent_1  |\u001b[0m Step 4/22 : RUN apt-get update -y && apt-get -y install --no-install-recommends default-jdk\n",
      "\u001b[36magent_1  |\u001b[0m  ---> Using cache\n",
      "\u001b[36magent_1  |\u001b[0m  ---> 9573566cf408\n",
      "\u001b[36magent_1  |\u001b[0m Step 5/22 : RUN rm -rf /var/lib/apt/lists/*\n",
      "\u001b[36magent_1  |\u001b[0m  ---> Using cache\n",
      "\u001b[36magent_1  |\u001b[0m  ---> be6f32780091\n",
      "\u001b[36magent_1  |\u001b[0m Step 6/22 : RUN pip --no-cache-dir install multi-model-server sagemaker-inference sagemaker-training\n",
      "\u001b[36magent_1  |\u001b[0m  ---> Using cache\n",
      "\u001b[36magent_1  |\u001b[0m  ---> 9026024a47b9\n",
      "\u001b[36magent_1  |\u001b[0m Step 7/22 : RUN pip --no-cache-dir install pandas numpy scipy scikit-learn\n",
      "\u001b[36magent_1  |\u001b[0m  ---> Using cache\n",
      "\u001b[36magent_1  |\u001b[0m  ---> 4a8b1f8822ea\n",
      "\u001b[36magent_1  |\u001b[0m Step 8/22 : ENV PYTHONUNBUFFERED=TRUE\n",
      "\u001b[36magent_1  |\u001b[0m  ---> Using cache\n",
      "\u001b[36magent_1  |\u001b[0m  ---> edf93ea7a7b9\n",
      "\u001b[36magent_1  |\u001b[0m Step 9/22 : ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
      "\u001b[36magent_1  |\u001b[0m  ---> Using cache\n",
      "\u001b[36magent_1  |\u001b[0m  ---> 1dedecf679e4\n",
      "\u001b[36magent_1  |\u001b[0m Step 10/22 : ENV PYTHONPATH=\"/opt/ml/code:${PATH}\"\n",
      "\u001b[36magent_1  |\u001b[0m  ---> Using cache\n",
      "\u001b[36magent_1  |\u001b[0m  ---> ed6a6a821886\n",
      "\u001b[36magent_1  |\u001b[0m Step 11/22 : ENV SM_INPUT /opt/ml/input\n",
      "\u001b[36magent_1  |\u001b[0m  ---> Using cache\n",
      "\u001b[36magent_1  |\u001b[0m  ---> 744511fe7ee1\n",
      "\u001b[36magent_1  |\u001b[0m Step 12/22 : ENV SM_INPUT_TRAINING_CONFIG_FILE $SM_INPUT/config/hyperparameters.json\n",
      "\u001b[36magent_1  |\u001b[0m  ---> Using cache\n",
      "\u001b[36magent_1  |\u001b[0m  ---> 377b7650dfa8\n",
      "\u001b[36magent_1  |\u001b[0m Step 13/22 : ENV SM_INPUT_DATA_CONFIG_FILE $SM_INPUT/config/inputdataconfig.json\n",
      "\u001b[36magent_1  |\u001b[0m  ---> Using cache\n",
      "\u001b[36magent_1  |\u001b[0m  ---> 02d2919f0283\n",
      "\u001b[36magent_1  |\u001b[0m Step 14/22 : ENV SM_CHECKPOINT_CONFIG_FILE $SM_INPUT/config/checkpointconfig.json\n",
      "\u001b[36magent_1  |\u001b[0m  ---> Using cache\n",
      "\u001b[36magent_1  |\u001b[0m  ---> b3b74c163fb8\n",
      "\u001b[36magent_1  |\u001b[0m Step 15/22 : ENV SM_MODEL_DIR /opt/ml/model\n",
      "\u001b[36magent_1  |\u001b[0m  ---> Using cache\n",
      "\u001b[36magent_1  |\u001b[0m  ---> 2faa8bc3f758\n",
      "\u001b[36magent_1  |\u001b[0m Step 16/22 : ENV CODE_DIR /opt/ml/code\n",
      "\u001b[36magent_1  |\u001b[0m  ---> Using cache\n",
      "\u001b[36magent_1  |\u001b[0m  ---> 881103ee9f05\n",
      "\u001b[36magent_1  |\u001b[0m Step 17/22 : COPY training.py $CODE_DIR/training.py\n",
      "\u001b[36magent_1  |\u001b[0m  ---> Using cache\n",
      "\u001b[36magent_1  |\u001b[0m  ---> 700944b70c00\n",
      "\u001b[36magent_1  |\u001b[0m Step 18/22 : COPY handler_service.py $CODE_DIR/handler_service.py\n",
      "\u001b[36magent_1  |\u001b[0m  ---> Using cache\n",
      "\u001b[36magent_1  |\u001b[0m  ---> efa3260a5064\n",
      "\u001b[36magent_1  |\u001b[0m Step 19/22 : COPY inference_handler.py $CODE_DIR/inference_handler.py\n",
      "\u001b[36magent_1  |\u001b[0m  ---> Using cache\n",
      "\u001b[36magent_1  |\u001b[0m  ---> ddb703a11bab\n",
      "\u001b[36magent_1  |\u001b[0m Step 20/22 : COPY serving.py $CODE_DIR/serving.py\n",
      "\u001b[36magent_1  |\u001b[0m  ---> Using cache\n",
      "\u001b[36magent_1  |\u001b[0m  ---> 172c8feb8f49\n",
      "\u001b[36magent_1  |\u001b[0m Step 21/22 : ENV SAGEMAKER_TRAINING_MODULE training:main\n",
      "\u001b[36magent_1  |\u001b[0m  ---> Using cache\n",
      "\u001b[36magent_1  |\u001b[0m  ---> 1f78c4063698\n",
      "\u001b[36magent_1  |\u001b[0m Step 22/22 : ENV SAGEMAKER_SERVING_MODULE serving:main\n",
      "\u001b[36magent_1  |\u001b[0m  ---> Using cache\n",
      "\u001b[36magent_1  |\u001b[0m  ---> 0d9dabd3deb3\n",
      "\u001b[36magent_1  |\u001b[0m Successfully built 0d9dabd3deb3\n",
      "\u001b[36magent_1  |\u001b[0m Successfully tagged iris-model:test\n",
      "\u001b[36magent_1  |\u001b[0m \n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:45 Running command docker tag $IMAGE_REPO_NAME:$IMAGE_TAG $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG\n",
      "\u001b[36magent_1  |\u001b[0m \n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:45 Phase complete: BUILD State: SUCCEEDED\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:45 Phase context status code:  Message: \n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:45 Entering phase POST_BUILD\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:45 Running command echo Build completed on `date`\n",
      "\u001b[36magent_1  |\u001b[0m Build completed on Sun Jul 19 01:11:45 UTC 2020\n",
      "\u001b[36magent_1  |\u001b[0m \n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:45 Running command echo Pushing the Docker image...\n",
      "\u001b[36magent_1  |\u001b[0m Pushing the Docker image...\n",
      "\u001b[36magent_1  |\u001b[0m \n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:45 Running command echo docker push $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG\n",
      "\u001b[36magent_1  |\u001b[0m docker push 725879053979.dkr.ecr.us-east-1.amazonaws.com/iris-model:test\n",
      "\u001b[36magent_1  |\u001b[0m \n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:11:45 Running command docker push $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG\n",
      "\u001b[36magent_1  |\u001b[0m The push refers to repository [725879053979.dkr.ecr.us-east-1.amazonaws.com/iris-model]\n",
      "\u001b[36magent_1  |\u001b[0m 128bcde6208b: Preparing\n",
      "\u001b[36magent_1  |\u001b[0m 2d733ae4b0e4: Preparing\n",
      "\u001b[36magent_1  |\u001b[0m 46fde1d9c157: Preparing\n",
      "\u001b[36magent_1  |\u001b[0m bd48c3aeea6d: Preparing\n",
      "\u001b[36magent_1  |\u001b[0m 854ec304b9e1: Preparing\n",
      "\u001b[36magent_1  |\u001b[0m f2b8baa9bbe1: Preparing\n",
      "\u001b[36magent_1  |\u001b[0m bd070b0e24c9: Preparing\n",
      "\u001b[36magent_1  |\u001b[0m 34c4b72d562c: Preparing\n",
      "\u001b[36magent_1  |\u001b[0m f1535a5a6c0c: Preparing\n",
      "\u001b[36magent_1  |\u001b[0m 3e01f9fd787f: Preparing\n",
      "\u001b[36magent_1  |\u001b[0m 646632873240: Preparing\n",
      "\u001b[36magent_1  |\u001b[0m 98d95bdfa037: Preparing\n",
      "\u001b[36magent_1  |\u001b[0m da9418a2e1b1: Preparing\n",
      "\u001b[36magent_1  |\u001b[0m 2e5b4ca91984: Preparing\n",
      "\u001b[36magent_1  |\u001b[0m 527ade4639e0: Preparing\n",
      "\u001b[36magent_1  |\u001b[0m c2c789d2d3c5: Preparing\n",
      "\u001b[36magent_1  |\u001b[0m 8803ef42039d: Preparing\n",
      "\u001b[36magent_1  |\u001b[0m f1535a5a6c0c: Waiting\n",
      "\u001b[36magent_1  |\u001b[0m 3e01f9fd787f: Waiting\n",
      "\u001b[36magent_1  |\u001b[0m 646632873240: Waiting\n",
      "\u001b[36magent_1  |\u001b[0m 98d95bdfa037: Waiting\n",
      "\u001b[36magent_1  |\u001b[0m bd070b0e24c9: Waiting\n",
      "\u001b[36magent_1  |\u001b[0m da9418a2e1b1: Waiting\n",
      "\u001b[36magent_1  |\u001b[0m 2e5b4ca91984: Waiting\n",
      "\u001b[36magent_1  |\u001b[0m 34c4b72d562c: Waiting\n",
      "\u001b[36magent_1  |\u001b[0m 527ade4639e0: Waiting\n",
      "\u001b[36magent_1  |\u001b[0m f2b8baa9bbe1: Waiting\n",
      "\u001b[36magent_1  |\u001b[0m c2c789d2d3c5: Waiting\n",
      "\u001b[36magent_1  |\u001b[0m 8803ef42039d: Waiting\n",
      "\u001b[36magent_1  |\u001b[0m 2d733ae4b0e4: Pushed\n",
      "\u001b[36magent_1  |\u001b[0m 128bcde6208b: Pushed\n",
      "\u001b[36magent_1  |\u001b[0m bd48c3aeea6d: Pushed\n",
      "\u001b[36magent_1  |\u001b[0m 46fde1d9c157: Pushed\n",
      "\u001b[36magent_1  |\u001b[0m bd070b0e24c9: Pushed\n",
      "\u001b[36magent_1  |\u001b[0m 3e01f9fd787f: Pushed\n",
      "\u001b[36magent_1  |\u001b[0m f1535a5a6c0c: Pushed\n",
      "\u001b[36magent_1  |\u001b[0m 98d95bdfa037: Pushed\n",
      "\u001b[36magent_1  |\u001b[0m 854ec304b9e1: Pushed\n",
      "\u001b[36magent_1  |\u001b[0m 646632873240: Pushed\n",
      "\u001b[36magent_1  |\u001b[0m 527ade4639e0: Pushed\n",
      "\u001b[36magent_1  |\u001b[0m c2c789d2d3c5: Pushed\n",
      "\u001b[36magent_1  |\u001b[0m f2b8baa9bbe1: Pushed\n",
      "\u001b[36magent_1  |\u001b[0m 2e5b4ca91984: Pushed\n",
      "\u001b[36magent_1  |\u001b[0m 8803ef42039d: Pushed\n",
      "\u001b[36magent_1  |\u001b[0m 34c4b72d562c: Pushed\n",
      "\u001b[36magent_1  |\u001b[0m da9418a2e1b1: Pushed\n",
      "\u001b[36magent_1  |\u001b[0m test: digest: sha256:fa13804f99ef839f111cfe03441b489e25eef563fcfbc780da9420a9ad44f770 size: 3891\n",
      "\u001b[36magent_1  |\u001b[0m \n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:12:30 Running command echo $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG > image.url\n",
      "\u001b[36magent_1  |\u001b[0m \n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:12:30 Running command echo Done\n",
      "\u001b[36magent_1  |\u001b[0m Done\n",
      "\u001b[36magent_1  |\u001b[0m \n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:12:30 Phase complete: POST_BUILD State: SUCCEEDED\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:12:30 Phase context status code:  Message: \n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:12:30 Expanding base directory path: .\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:12:30 Assembling file list\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:12:30 Expanding .\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:12:30 Expanding file paths for base directory .\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:12:30 Assembling file list\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:12:30 Expanding image.url\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:12:30 Found 1 file(s)\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:12:30 Preparing to copy secondary artifacts\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:12:30 No secondary artifacts defined in buildspec\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:12:30 Phase complete: UPLOAD_ARTIFACTS State: SUCCEEDED\n",
      "\u001b[36magent_1  |\u001b[0m [Container] 2020/07/19 01:12:30 Phase context status code:  Message: \n",
      "\u001b[33magent-resources_build_1 exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "CPU times: user 962 ms, sys: 167 ms, total: 1.13 s\n",
      "Wall time: 53.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "!/tmp/aws-codebuild/local_builds/codebuild_build.sh \\\n",
    "    -a \"$PWD/tests/output\" \\\n",
    "    -s \"$PWD/tests\" \\\n",
    "    -i \"samirsouza/aws-codebuild-standard:3.0\" \\\n",
    "    -e \"$PWD/tests/vars.env\" \\\n",
    "    -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now that we have an image deployed in the ECR repo we can also run some local tests using the SageMaker Estimator.\n",
    "\n",
    "> Click on this [TEST NOTEBOOK](03_Testing%20the%20container%20using%20SageMaker%20Estimator.ipynb) to run some tests.\n",
    "\n",
    "> After you finishing the tests, come back to **this notebook** to push the assets to the Git Repo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 4 - Let's push all the assets to the Git Repo connected to the Build pipeline\n",
    "There is a CodePipeine configured to keep listeining to this Git Repo and start a new Building process with CodeBuild."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd ../../../mlops\n",
    "git checkout iris_model\n",
    "cp $OLDPWD/buildspec.yml $OLDPWD/handler.py $OLDPWD/train.py $OLDPWD/main.py $OLDPWD/Dockerfile .\n",
    "\n",
    "git add --all\n",
    "git commit -a -m \" - files for building an iris model image\"\n",
    "git push"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Alright, now open the AWS console and go to the **CodePipeline** dashboard. Look for a pipeline called **mlops-iris-model**. This pipeline will deploy the final image to an ECR repo. When this process finishes, open the **Elastic Compute Registry** dashboard, in the AWS console, and check if you have an image called **iris-model:latest**. If yes, you can go to the next exercise. If not, wait a little more."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
